{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Time_Series task.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reinforcement Learning"
      ],
      "metadata": {
        "id": "F4cLHdzi3WJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RL libraries for Time Series Forecating\n",
        "\n",
        "\n",
        "1.   AutoTs\n",
        "2.   Darts\n",
        "3.   Kats\n",
        "4.   GreyKite\n",
        "5.   TsFresh\n",
        "\n"
      ],
      "metadata": {
        "id": "9gCClTkN5aEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing"
      ],
      "metadata": {
        "id": "99V6H-TBlLn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "5bfn6xcd3aBE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv('AirPassengers.csv')"
      ],
      "metadata": {
        "id": "0P280Ozw4Lf0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "r1jONcgS86-g",
        "outputId": "4ef1e85d-158d-4ea1-e298-3a369b44520e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Month  #Passengers\n",
              "0    1949-01          112\n",
              "1    1949-02          118\n",
              "2    1949-03          132\n",
              "3    1949-04          129\n",
              "4    1949-05          121\n",
              "..       ...          ...\n",
              "139  1960-08          606\n",
              "140  1960-09          508\n",
              "141  1960-10          461\n",
              "142  1960-11          390\n",
              "143  1960-12          432\n",
              "\n",
              "[144 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76aeda8a-20af-4d65-afa9-918399e96559\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>#Passengers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1949-01</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1949-02</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1949-03</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1949-04</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1949-05</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1960-08</td>\n",
              "      <td>606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1960-09</td>\n",
              "      <td>508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>1960-10</td>\n",
              "      <td>461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>1960-11</td>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1960-12</td>\n",
              "      <td>432</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>144 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76aeda8a-20af-4d65-afa9-918399e96559')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76aeda8a-20af-4d65-afa9-918399e96559 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76aeda8a-20af-4d65-afa9-918399e96559');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pPRdTwG887lq",
        "outputId": "9d56a74e-4e25-4546-e674-262020cb8d84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Month  #Passengers\n",
              "0    False        False\n",
              "1    False        False\n",
              "2    False        False\n",
              "3    False        False\n",
              "4    False        False\n",
              "..     ...          ...\n",
              "139  False        False\n",
              "140  False        False\n",
              "141  False        False\n",
              "142  False        False\n",
              "143  False        False\n",
              "\n",
              "[144 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c5a713c-20d2-4cda-8ab1-cc07778d5aeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>#Passengers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>144 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c5a713c-20d2-4cda-8ab1-cc07778d5aeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c5a713c-20d2-4cda-8ab1-cc07778d5aeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c5a713c-20d2-4cda-8ab1-cc07778d5aeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(data.isnull())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "xq-DdpvL89vc",
        "outputId": "cb9f4c7b-ee33-4aee-d0bb-94427e0cd864"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9efd57aa90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g04aFCT-9BSC",
        "outputId": "30d641d8-fb62-4179-bf71-107e6aab2818"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 144 entries, 0 to 143\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Month        144 non-null    object\n",
            " 1   #Passengers  144 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kats\n",
        "\n",
        "Kats (Kits to Analyze Time Series) is an open-source Python library developed by researchers at Facebook (now Meta). This library is easy to use and is helpful for time series problems. This is due to its very light weighted library of generic time series analysis which allows to set up the models quicker without spending so much time processing time series and calculations in different models."
      ],
      "metadata": {
        "id": "SOJ9IzTJaSP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kats"
      ],
      "metadata": {
        "id": "I5jpXS69guYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ShO0TfeDkpUZ",
        "outputId": "c58cb58d-c306-466a-cfa5-7785094e8b90"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         month  #Passengers\n",
              "0   1949-01-01          112\n",
              "1   1949-02-01          118\n",
              "2   1949-03-01          132\n",
              "3   1949-04-01          129\n",
              "4   1949-05-01          121\n",
              "..         ...          ...\n",
              "139 1960-08-01          606\n",
              "140 1960-09-01          508\n",
              "141 1960-10-01          461\n",
              "142 1960-11-01          390\n",
              "143 1960-12-01          432\n",
              "\n",
              "[144 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48e22ff8-761c-470d-a55b-f94bf2bc4a99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>#Passengers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1949-01-01</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1949-02-01</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1949-03-01</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1949-04-01</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1949-05-01</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1960-08-01</td>\n",
              "      <td>606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1960-09-01</td>\n",
              "      <td>508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>1960-10-01</td>\n",
              "      <td>461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>1960-11-01</td>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1960-12-01</td>\n",
              "      <td>432</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>144 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48e22ff8-761c-470d-a55b-f94bf2bc4a99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48e22ff8-761c-470d-a55b-f94bf2bc4a99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48e22ff8-761c-470d-a55b-f94bf2bc4a99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kats.consts import TimeSeriesData\n",
        "from kats.models.prophet import ProphetModel, ProphetParams\n",
        "data.columns = ['month','#Passengers']\n",
        "data['month'] = pd.to_datetime(data['month'],infer_datetime_format=True,format='%y%m')\n",
        "df_s = TimeSeriesData(time=data['month'], value=data['#Passengers'])\n",
        "df_s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GCA13ngbhRF9",
        "outputId": "e940b47f-8f32-4eb5-c883-3145c018cf89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         month  #Passengers\n",
              "0   1949-01-01          112\n",
              "1   1949-02-01          118\n",
              "2   1949-03-01          132\n",
              "3   1949-04-01          129\n",
              "4   1949-05-01          121\n",
              "..         ...          ...\n",
              "139 1960-08-01          606\n",
              "140 1960-09-01          508\n",
              "141 1960-10-01          461\n",
              "142 1960-11-01          390\n",
              "143 1960-12-01          432\n",
              "\n",
              "[144 rows x 2 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>#Passengers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1949-01-01</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1949-02-01</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1949-03-01</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1949-04-01</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1949-05-01</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1960-08-01</td>\n",
              "      <td>606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1960-09-01</td>\n",
              "      <td>508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>1960-10-01</td>\n",
              "      <td>461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>1960-11-01</td>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1960-12-01</td>\n",
              "      <td>432</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>144 rows Ã— 2 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model param instance\n",
        "params = ProphetParams(seasonality_mode='multiplicative')\n",
        "# create a prophet model instance\n",
        "model = ProphetModel(df_s, params)\n",
        "# fit model simply by calling m.fit()\n",
        "model.fit()\n",
        "# make prediction for next 30 month\n",
        "forecast = model.predict(steps=30, freq=\"MS\")\n",
        "forecast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6xpC5dAfkn_o",
        "outputId": "18e4a238-f4ee-4497-e2ea-3f9d9c763980"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         time        fcst  fcst_lower  fcst_upper\n",
              "0  1961-01-01  451.765190  438.395440  464.096743\n",
              "1  1961-02-01  433.212698  419.929813  445.667075\n",
              "2  1961-03-01  492.254622  479.347315  506.742135\n",
              "3  1961-04-01  495.496541  482.047698  508.554853\n",
              "4  1961-05-01  504.186375  490.909704  516.536063\n",
              "5  1961-06-01  579.977736  566.351321  593.453518\n",
              "6  1961-07-01  654.295383  640.856260  666.937590\n",
              "7  1961-08-01  650.455654  637.313855  664.119644\n",
              "8  1961-09-01  553.650426  541.376335  567.019859\n",
              "9  1961-10-01  489.740913  476.763060  502.807180\n",
              "10 1961-11-01  425.141438  412.384177  438.248090\n",
              "11 1961-12-01  474.208683  460.230643  486.797642\n",
              "12 1962-01-01  490.122729  476.469062  503.725333\n",
              "13 1962-02-01  469.423125  456.962265  482.918478\n",
              "14 1962-03-01  540.012760  526.270228  553.912637\n",
              "15 1962-04-01  530.402750  515.991604  544.005981\n",
              "16 1962-05-01  546.367053  532.655146  560.523601\n",
              "17 1962-06-01  624.816026  610.516803  639.553784\n",
              "18 1962-07-01  709.180935  695.117246  723.404063\n",
              "19 1962-08-01  708.040801  693.756602  724.023583\n",
              "20 1962-09-01  600.483421  586.181286  613.877726\n",
              "21 1962-10-01  526.126803  511.050969  540.869350\n",
              "22 1962-11-01  458.139022  443.976688  472.409735\n",
              "23 1962-12-01  511.997608  496.927440  527.108489\n",
              "24 1963-01-01  528.451589  513.380690  543.339099\n",
              "25 1963-02-01  505.633414  490.155136  520.619779\n",
              "26 1963-03-01  588.597725  573.913070  604.294522\n",
              "27 1963-04-01  564.170537  548.389887  580.371239\n",
              "28 1963-05-01  588.634028  572.497219  604.012630\n",
              "29 1963-06-01  669.237827  652.094494  686.335499"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e929957-4bec-400d-bb31-a19a5744a913\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>fcst</th>\n",
              "      <th>fcst_lower</th>\n",
              "      <th>fcst_upper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1961-01-01</td>\n",
              "      <td>451.765190</td>\n",
              "      <td>438.395440</td>\n",
              "      <td>464.096743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1961-02-01</td>\n",
              "      <td>433.212698</td>\n",
              "      <td>419.929813</td>\n",
              "      <td>445.667075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1961-03-01</td>\n",
              "      <td>492.254622</td>\n",
              "      <td>479.347315</td>\n",
              "      <td>506.742135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1961-04-01</td>\n",
              "      <td>495.496541</td>\n",
              "      <td>482.047698</td>\n",
              "      <td>508.554853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1961-05-01</td>\n",
              "      <td>504.186375</td>\n",
              "      <td>490.909704</td>\n",
              "      <td>516.536063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1961-06-01</td>\n",
              "      <td>579.977736</td>\n",
              "      <td>566.351321</td>\n",
              "      <td>593.453518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1961-07-01</td>\n",
              "      <td>654.295383</td>\n",
              "      <td>640.856260</td>\n",
              "      <td>666.937590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1961-08-01</td>\n",
              "      <td>650.455654</td>\n",
              "      <td>637.313855</td>\n",
              "      <td>664.119644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1961-09-01</td>\n",
              "      <td>553.650426</td>\n",
              "      <td>541.376335</td>\n",
              "      <td>567.019859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1961-10-01</td>\n",
              "      <td>489.740913</td>\n",
              "      <td>476.763060</td>\n",
              "      <td>502.807180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1961-11-01</td>\n",
              "      <td>425.141438</td>\n",
              "      <td>412.384177</td>\n",
              "      <td>438.248090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1961-12-01</td>\n",
              "      <td>474.208683</td>\n",
              "      <td>460.230643</td>\n",
              "      <td>486.797642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1962-01-01</td>\n",
              "      <td>490.122729</td>\n",
              "      <td>476.469062</td>\n",
              "      <td>503.725333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1962-02-01</td>\n",
              "      <td>469.423125</td>\n",
              "      <td>456.962265</td>\n",
              "      <td>482.918478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1962-03-01</td>\n",
              "      <td>540.012760</td>\n",
              "      <td>526.270228</td>\n",
              "      <td>553.912637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1962-04-01</td>\n",
              "      <td>530.402750</td>\n",
              "      <td>515.991604</td>\n",
              "      <td>544.005981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1962-05-01</td>\n",
              "      <td>546.367053</td>\n",
              "      <td>532.655146</td>\n",
              "      <td>560.523601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1962-06-01</td>\n",
              "      <td>624.816026</td>\n",
              "      <td>610.516803</td>\n",
              "      <td>639.553784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1962-07-01</td>\n",
              "      <td>709.180935</td>\n",
              "      <td>695.117246</td>\n",
              "      <td>723.404063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1962-08-01</td>\n",
              "      <td>708.040801</td>\n",
              "      <td>693.756602</td>\n",
              "      <td>724.023583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1962-09-01</td>\n",
              "      <td>600.483421</td>\n",
              "      <td>586.181286</td>\n",
              "      <td>613.877726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1962-10-01</td>\n",
              "      <td>526.126803</td>\n",
              "      <td>511.050969</td>\n",
              "      <td>540.869350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1962-11-01</td>\n",
              "      <td>458.139022</td>\n",
              "      <td>443.976688</td>\n",
              "      <td>472.409735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1962-12-01</td>\n",
              "      <td>511.997608</td>\n",
              "      <td>496.927440</td>\n",
              "      <td>527.108489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1963-01-01</td>\n",
              "      <td>528.451589</td>\n",
              "      <td>513.380690</td>\n",
              "      <td>543.339099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1963-02-01</td>\n",
              "      <td>505.633414</td>\n",
              "      <td>490.155136</td>\n",
              "      <td>520.619779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1963-03-01</td>\n",
              "      <td>588.597725</td>\n",
              "      <td>573.913070</td>\n",
              "      <td>604.294522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1963-04-01</td>\n",
              "      <td>564.170537</td>\n",
              "      <td>548.389887</td>\n",
              "      <td>580.371239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1963-05-01</td>\n",
              "      <td>588.634028</td>\n",
              "      <td>572.497219</td>\n",
              "      <td>604.012630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1963-06-01</td>\n",
              "      <td>669.237827</td>\n",
              "      <td>652.094494</td>\n",
              "      <td>686.335499</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e929957-4bec-400d-bb31-a19a5744a913')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e929957-4bec-400d-bb31-a19a5744a913 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e929957-4bec-400d-bb31-a19a5744a913');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "YbUY_QVRkz9O",
        "outputId": "3dc14d47-524f-447e-f950-acf429375c83"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9efd56e190>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoTs\n",
        "\n",
        "AutoTS- Python time series tool, stands for Automatic Time Series, quickly providing high-accuracy forecasts at scale. It offers many different forecasting models and functions directly compatible with pandasâ€™ data frames. "
      ],
      "metadata": {
        "id": "v9zLWjA1TuCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install autots"
      ],
      "metadata": {
        "id": "GZTEB9FFTwe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autots import AutoTS\n"
      ],
      "metadata": {
        "id": "o3H9vxdpTys1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autots import AutoTS\n",
        "model = AutoTS(forecast_length=12, frequency='infer',ensemble='simple')\n",
        "model = model.fit(data, date_col='month', value_col='#Passengers', id_col=None)\n",
        "prediction = model.predict()\n",
        "#make predictions\n",
        "forecast = prediction.forecast\n",
        "print(\"Passengers Forecast\")\n",
        "print(forecast)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg-GaSnOT_eh",
        "outputId": "a77a8e13-7ca7-4eb9-9351-bab1d1236d02"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred frequency is: MS\n",
            "Model Number: 1 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 2 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 3 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 4 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 5 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 6 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 7 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 12s 11ms/step - loss: 0.3799\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3801\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3794\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3818\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3812\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3801\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3750\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3777\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3831\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3747\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3779\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3746\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3778\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3757\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3772\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3744\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3749\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3752\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3774\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3731\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3746\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3724\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3736\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3729\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3754\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3768\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3791\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3726\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3729\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3744\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3739\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3781\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3761\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3743\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3699\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3731\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3708\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3713\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3671\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3714\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3733\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3646\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3733\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3728\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3688\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3665\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3635\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3680\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3679\n",
            "Model Number: 8 with model ETS in generation 0 of 10\n",
            "Model Number: 9 with model ETS in generation 0 of 10\n",
            "Model Number: 10 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 10: GLM\n",
            "Model Number: 11 with model GLM in generation 0 of 10\n",
            "Model Number: 12 with model GLS in generation 0 of 10\n",
            "Model Number: 13 with model GLS in generation 0 of 10\n",
            "Model Number: 14 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 14: GluonTS\n",
            "Model Number: 15 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 15: GluonTS\n",
            "Model Number: 16 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 16: GluonTS\n",
            "Model Number: 17 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 17: GluonTS\n",
            "Model Number: 18 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 18: GluonTS\n",
            "Model Number: 19 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 20 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 21 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 22 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 23 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 24 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 25 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 26 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 27 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 28 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 29 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 29: VAR\n",
            "Model Number: 30 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30: VAR\n",
            "Model Number: 31 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 31: VECM\n",
            "Model Number: 32 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32: VECM\n",
            "Model Number: 33 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 34 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 35 with model FBProphet in generation 0 of 10\n",
            "Model Number: 36 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 36: GluonTS\n",
            "Model Number: 37 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 38 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 38: MultivariateRegression\n",
            "Model Number: 39 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 39: DatepartRegression\n",
            "Model Number: 40 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 41 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 42 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 43 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 44 with model ETS in generation 0 of 10\n",
            "Model Number: 45 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 45: VECM\n",
            "Model Number: 46 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 46: ARDL\n",
            "Model Number: 47 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 48 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 49 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 50 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 51 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 52 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 53 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 54 with model FBProphet in generation 0 of 10\n",
            "Model Number: 55 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 56 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 57 with model NVAR in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 58 with model Theta in generation 0 of 10\n",
            "Model Number: 59 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 59: UnivariateRegression\n",
            "Model Number: 60 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 61 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 62 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 63 with model GLS in generation 0 of 10\n",
            "Model Number: 64 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 65 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 65: GLM\n",
            "Model Number: 66 with model ETS in generation 0 of 10\n",
            "Model Number: 67 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 68 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 68: GluonTS\n",
            "Model Number: 69 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 70 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 70: VAR\n",
            "Model Number: 71 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 71: VECM\n",
            "Model Number: 72 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: LightGBMError('[tweedie]: at least one target label is negative') in model 72: WindowRegression\n",
            "Model Number: 73 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 73: DatepartRegression\n",
            "Model Number: 74 with model UnivariateRegression in generation 0 of 10\n",
            "Model Number: 75 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 75: MultivariateRegression\n",
            "Model Number: 76 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 77 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 78 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('Model SectionalMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 78: SectionalMotif\n",
            "Model Number: 79 with model NVAR in generation 0 of 10\n",
            "Model Number: 80 with model Theta in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/percentile.py:47: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 81 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 81: ARDL\n",
            "Model Number: 82 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 82: VAR\n",
            "Model Number: 83 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 84 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 84: GLM\n",
            "Model Number: 85 with model NVAR in generation 0 of 10\n",
            "Model Number: 86 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 87 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 88 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 89 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 90 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 91 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 91: GLM\n",
            "Model Number: 92 with model ConstantNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on inverse') in model 92: ConstantNaive\n",
            "Model Number: 93 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 93: GLM\n",
            "Model Number: 94 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 95 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 96 with model GLS in generation 0 of 10\n",
            "Model Number: 97 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 97: UnobservedComponents\n",
            "Model Number: 98 with model ETS in generation 0 of 10\n",
            "Model Number: 99 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('kth(=10) out of bounds (5)') in model 99: UnivariateMotif\n",
            "Model Number: 100 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 101 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 102 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 102: VAR\n",
            "Model Number: 103 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 104 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 105 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 106 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('Model MultivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 106: MultivariateMotif\n",
            "Model Number: 107 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 108 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 109 with model Theta in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:48: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in reduce\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 110 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 111 with model NVAR in generation 0 of 10\n",
            "Model Number: 112 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 113 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 114 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 115 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 6s 18ms/step - loss: 98.5201\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.7304\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 98.1111\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.1792\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.0020\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 99.1413\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.9287\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.9134\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.9954\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.2138\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 98.4827\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.0347\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.8230\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 97.0057\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 96.5959\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.2141\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.0755\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 97.2315\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 97.2178\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.5123\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.3244\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.5472\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 97.4305\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.3076\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.8642\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.1744\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.8919\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 97.8139\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.3589\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.4761\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.1675\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.8303\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.5008\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.7752\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.9233\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 97.3949\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 98.0922\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.9160\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.0001\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 97.3646\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 97.1280\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.6221\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 97.1364\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 97.3635\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 96.9461\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 98.1626\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 97.0497\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.9664\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 96.9867\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 96.9695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 116 with model FBProphet in generation 0 of 10\n",
            "Model Number: 117 with model ETS in generation 0 of 10\n",
            "Model Number: 118 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 119 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 120 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 121 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 122 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 123 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 123: VAR\n",
            "Model Number: 124 with model GLS in generation 0 of 10\n",
            "Model Number: 125 with model WindowRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 5s 5ms/step - loss: nan\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Model Number: 126 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 127 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 127: WindowRegression\n",
            "Model Number: 128 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 129 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'zero', 'transformations': {'0': 'CumSumTransformer', '1': 'cffilter', '2': 'IntermittentOccurrence'}, 'transformation_params': {'0': {}, '1': {}, '2': {'center': 'mean'}}}. fail_on_forecast_nan=True\") in model 129: MultivariateMotif\n",
            "Model Number: 130 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 130: ARDL\n",
            "Model Number: 131 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 132 with model ETS in generation 0 of 10\n",
            "Model Number: 133 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 133: UnobservedComponents\n",
            "Model Number: 134 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer StandardScaler failed on fit') in model 134: DatepartRegression\n",
            "Model Number: 135 with model NVAR in generation 0 of 10\n",
            "Model Number: 136 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 137 with model NVAR in generation 0 of 10\n",
            "Model Number: 138 with model SeasonalNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning:\n",
            "\n",
            "Feature names only support names that are all strings. Got feature names with dtypes: ['Timestamp', 'str']. An error will be raised in 1.2.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:985: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:990: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:1020: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning:\n",
            "\n",
            "Feature names only support names that are all strings. Got feature names with dtypes: ['Timestamp', 'str']. An error will be raised in 1.2.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 139 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 140 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 141 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 142 with model ETS in generation 0 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 143 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 143: ARDL\n",
            "Model Number: 144 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 145 with model NVAR in generation 0 of 10\n",
            "Model Number: 146 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 146: VAR\n",
            "Model Number: 147 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 148 with model GLS in generation 0 of 10\n",
            "Model Number: 149 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 150 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 151 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 152 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 153 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 154 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 155 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 155: GluonTS\n",
            "Model Number: 156 with model VAR in generation 0 of 10\n",
            "Template Eval Error: IndexError('tuple index out of range') in model 156: VAR\n",
            "Model Number: 157 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 158 with model GLS in generation 0 of 10\n",
            "Model Number: 159 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 159: GLM\n",
            "Model Number: 160 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 161 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 162 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 162: VAR\n",
            "Model Number: 163 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 164 with model NVAR in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:428: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:134: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 165 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 165: GluonTS\n",
            "Model Number: 166 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 167 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 167: ARDL\n",
            "Model Number: 168 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type=='User' but no future_regressor supplied\") in model 168: SectionalMotif\n",
            "Model Number: 169 with model AverageValueNaive in generation 0 of 10\n",
            "New Generation: 1 of 10\n",
            "Model Number: 170 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 170: DatepartRegression\n",
            "Model Number: 171 with model Theta in generation 1 of 10\n",
            "Model Number: 172 with model Theta in generation 1 of 10\n",
            "Model Number: 173 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 174 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 175 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 176 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 177 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 178 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 179 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 180 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 181 with model Theta in generation 1 of 10\n",
            "Model Number: 182 with model NVAR in generation 1 of 10\n",
            "Model Number: 183 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 184 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 185 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 185: UnobservedComponents\n",
            "Model Number: 186 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 187 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 188 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 189 with model ETS in generation 1 of 10\n",
            "Model Number: 190 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 191 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 192 with model Theta in generation 1 of 10\n",
            "Model Number: 193 with model ETS in generation 1 of 10\n",
            "Model Number: 194 with model NVAR in generation 1 of 10\n",
            "Model Number: 195 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 196 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 197 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 198 with model ETS in generation 1 of 10\n",
            "Model Number: 199 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 200 with model Theta in generation 1 of 10\n",
            "Model Number: 201 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 202 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 203 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 204 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 205 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 206 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 207 with model ETS in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 208 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 209 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 209: DatepartRegression\n",
            "Model Number: 210 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 210: DatepartRegression\n",
            "Model Number: 211 with model Theta in generation 1 of 10\n",
            "Model Number: 212 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 213 with model ETS in generation 1 of 10\n",
            "Model Number: 214 with model GLS in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 215 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 216 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 217 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 218 with model GLS in generation 1 of 10\n",
            "Model Number: 219 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 220 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 221 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 222 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 223 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 224 with model MultivariateRegression in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 225 with model MultivariateMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 226 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 227 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 228 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 229 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 230 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 231 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 232 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 233 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 234 with model ETS in generation 1 of 10\n",
            "Model Number: 235 with model MultivariateMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 236 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 237 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 238 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 239 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 240 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 241 with model SeasonalNaive in generation 1 of 10\n",
            "Template Eval Error: ValueError('Model SeasonalNaive returned NaN for one or more series. fail_on_forecast_nan=True') in model 241: SeasonalNaive\n",
            "Model Number: 242 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 243 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 244 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 245 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 246 with model LastValueNaive in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning:\n",
            "\n",
            "Feature names only support names that are all strings. Got feature names with dtypes: ['Timestamp', 'str']. An error will be raised in 1.2.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1376: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning:\n",
            "\n",
            "Feature names only support names that are all strings. Got feature names with dtypes: ['Timestamp', 'str']. An error will be raised in 1.2.\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 247 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer QuantileTransformer failed on fit') in model 247: DatepartRegression\n",
            "Model Number: 248 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 249 with model FBProphet in generation 1 of 10\n",
            "Model Number: 250 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 251 with model NVAR in generation 1 of 10\n",
            "Model Number: 252 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 253 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 254 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 255 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 256 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 257 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 0 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 258 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 259 with model ETS in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 260 with model FBProphet in generation 1 of 10\n",
            "Model Number: 261 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 262 with model WindowRegression in generation 1 of 10\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 6s 5ms/step - loss: nan\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: nan\n",
            "Model Number: 263 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 264 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 265 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 266 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 267 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 268 with model ETS in generation 1 of 10\n",
            "Model Number: 269 with model DatepartRegression in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 7ms/step - loss: 102.5745\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100.0933\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100.8067\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.6112\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 100.7908\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100.5312\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100.4980\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100.2294\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 99.4614\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.6461\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 100.4938\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.3488\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.7682\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.4621\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 98.9217\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.3536\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.3395\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.0997\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 100.0949\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.3876\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.1889\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 98.9674\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 100.2249\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 99.5379\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 100.2130\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 98.7347\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100.1273\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.5586\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.7782\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 98.9936\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 97.8259\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100.3675\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.0153\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 98.9907\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.5165\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.5802\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.0810\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 98.5783\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 97.6819\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 98.7999\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.6073\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 99.0882\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100.3753\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 98.7832\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 99.4572\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.8729\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.5324\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100.0065\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 99.1311\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 99.0417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9e152815f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 270 with model UnivariateMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 271 with model FBProphet in generation 1 of 10\n",
            "Model Number: 272 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 272: UnobservedComponents\n",
            "Model Number: 273 with model GLS in generation 1 of 10\n",
            "Model Number: 274 with model SeasonalNaive in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 275 with model FBProphet in generation 1 of 10\n",
            "Model Number: 276 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 277 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 278 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 279 with model LastValueNaive in generation 1 of 10\n",
            "New Generation: 2 of 10\n",
            "Model Number: 280 with model SeasonalNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 281 with model FBProphet in generation 2 of 10\n",
            "Model Number: 282 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 283 with model UnivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 283: UnivariateRegression\n",
            "Model Number: 284 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 285 with model Theta in generation 2 of 10\n",
            "Model Number: 286 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 287 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 288 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 289 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 290 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 291 with model NVAR in generation 2 of 10\n",
            "Model Number: 292 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 293 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 294 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 295 with model UnivariateMotif in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 296 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 297 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 298 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 299 with model Theta in generation 2 of 10\n",
            "Model Number: 300 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 301 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 302 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 303 with model Theta in generation 2 of 10\n",
            "Model Number: 304 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 305 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 306 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 307 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 308 with model Theta in generation 2 of 10\n",
            "Model Number: 309 with model ETS in generation 2 of 10\n",
            "Model Number: 310 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 311 with model Theta in generation 2 of 10\n",
            "Model Number: 312 with model Theta in generation 2 of 10\n",
            "Model Number: 313 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 314 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 315 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 316 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 317 with model SeasonalNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 318 with model GLS in generation 2 of 10\n",
            "Model Number: 319 with model Theta in generation 2 of 10\n",
            "Model Number: 320 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 321 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 322 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 323 with model ETS in generation 2 of 10\n",
            "Model Number: 324 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on #Passengers with ValueError('Can only dampen the trend component')\n",
            "Model Number: 325 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 326 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 327 with model NVAR in generation 2 of 10\n",
            "Model Number: 328 with model ConstantNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 328: ConstantNaive\n",
            "Model Number: 329 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 329: DatepartRegression\n",
            "Model Number: 330 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 331 with model UnobservedComponents in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 332 with model MultivariateRegression in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 333 with model WindowRegression in generation 2 of 10\n",
            "Template Eval Error: LightGBMError('[gamma]: at least one target label is negative') in model 333: WindowRegression\n",
            "Model Number: 334 with model Theta in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 335 with model FBProphet in generation 2 of 10\n",
            "Model Number: 336 with model WindowRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 336: WindowRegression\n",
            "Model Number: 337 with model Theta in generation 2 of 10\n",
            "Model Number: 338 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 339 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 340 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 341 with model GLS in generation 2 of 10\n",
            "Model Number: 342 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 343 with model FBProphet in generation 2 of 10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 344 with model FBProphet in generation 2 of 10\n",
            "Model Number: 345 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 346 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 347 with model ETS in generation 2 of 10\n",
            "Model Number: 348 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 349 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 350 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 351 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 352 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 353 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 354 with model NVAR in generation 2 of 10\n",
            "Model Number: 355 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 356 with model LastValueNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 356: LastValueNaive\n",
            "Model Number: 357 with model SeasonalNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 358 with model FBProphet in generation 2 of 10\n",
            "Model Number: 359 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 360 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 361 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 362 with model LastValueNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 362: LastValueNaive\n",
            "Model Number: 363 with model DatepartRegression in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 364 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 365 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 366 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 367 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 368 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 369 with model ETS in generation 2 of 10\n",
            "Model Number: 370 with model Theta in generation 2 of 10\n",
            "Model Number: 371 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 372 with model MultivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 372: MultivariateRegression\n",
            "Model Number: 373 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 374 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 375 with model NVAR in generation 2 of 10\n",
            "Model Number: 376 with model GLS in generation 2 of 10\n",
            "Model Number: 377 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 378 with model ETS in generation 2 of 10\n",
            "Model Number: 379 with model ConstantNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 380 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 381 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 382 with model GLS in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 382: GLS\n",
            "Model Number: 383 with model WindowRegression in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 384 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 385 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 386 with model UnivariateMotif in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 387 with model MultivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"loss='poisson' requires non-negative y and sum(y) > 0.\") in model 387: MultivariateRegression\n",
            "Model Number: 388 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 389 with model UnobservedComponents in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning:\n",
            "\n",
            "Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Generation: 3 of 10\n",
            "Model Number: 390 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 391 with model Theta in generation 3 of 10\n",
            "Model Number: 392 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 393 with model WindowRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 393: WindowRegression\n",
            "Model Number: 394 with model GLS in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 394: GLS\n",
            "Model Number: 395 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 396 with model GLS in generation 3 of 10\n",
            "Model Number: 397 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 398 with model WindowRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 398: WindowRegression\n",
            "Model Number: 399 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 400 with model ETS in generation 3 of 10\n",
            "Model Number: 401 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 402 with model MultivariateRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 403 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 404 with model UnivariateMotif in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 405 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 406 with model ETS in generation 3 of 10\n",
            "Model Number: 407 with model DatepartRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 408 with model GLS in generation 3 of 10\n",
            "Model Number: 409 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 410 with model LastValueNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 410: LastValueNaive\n",
            "Model Number: 411 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 412 with model MultivariateRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 413 with model GLS in generation 3 of 10\n",
            "Model Number: 414 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 415 with model FBProphet in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 415: FBProphet\n",
            "Model Number: 416 with model AverageValueNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 416: AverageValueNaive\n",
            "Model Number: 417 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 418 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 419 with model SeasonalNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 419: SeasonalNaive\n",
            "Model Number: 420 with model GLS in generation 3 of 10\n",
            "Model Number: 421 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 422 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 423 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 424 with model GLS in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 425 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 426 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 427 with model GLS in generation 3 of 10\n",
            "Model Number: 428 with model DatepartRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 429 with model SectionalMotif in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 430 with model Theta in generation 3 of 10\n",
            "Model Number: 431 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 432 with model NVAR in generation 3 of 10\n",
            "Model Number: 433 with model DatepartRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 434 with model FBProphet in generation 3 of 10\n",
            "Model Number: 435 with model UnobservedComponents in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 436 with model FBProphet in generation 3 of 10\n",
            "Model Number: 437 with model ETS in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 437: ETS\n",
            "Model Number: 438 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 439 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 440 with model DatepartRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 440: DatepartRegression\n",
            "Model Number: 441 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 442 with model MultivariateRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 443 with model ConstantNaive in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 444 with model FBProphet in generation 3 of 10\n",
            "Model Number: 445 with model Theta in generation 3 of 10\n",
            "Model Number: 446 with model Theta in generation 3 of 10\n",
            "Model Number: 447 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 448 with model Theta in generation 3 of 10\n",
            "Model Number: 449 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 450 with model DatepartRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 450: DatepartRegression\n",
            "Model Number: 451 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 452 with model WindowRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 453 with model NVAR in generation 3 of 10\n",
            "Model Number: 454 with model SectionalMotif in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 455 with model Theta in generation 3 of 10\n",
            "Model Number: 456 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 457 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 458 with model DatepartRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 458: DatepartRegression\n",
            "Model Number: 459 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 460 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 461 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 462 with model Theta in generation 3 of 10\n",
            "Model Number: 463 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 464 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 465 with model NVAR in generation 3 of 10\n",
            "Model Number: 466 with model UnobservedComponents in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 467 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 468 with model Theta in generation 3 of 10\n",
            "Model Number: 469 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "7/7 [==============================] - 6s 183ms/step - loss: 2.7514 - val_loss: 1.4594\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 1.8444 - val_loss: 0.5624\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 1.9910 - val_loss: 0.4760\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 1s 93ms/step - loss: 1.5210 - val_loss: 0.4660\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 1.6136 - val_loss: 0.4066\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 1.6888 - val_loss: 0.3469\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 1.6832 - val_loss: 0.3246\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 2.0667 - val_loss: 0.3260\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 1.8337 - val_loss: 0.3349\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 1.4881 - val_loss: 0.3028\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 1.9209 - val_loss: 0.3047\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 1.8286 - val_loss: 0.2971\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 1.7190 - val_loss: 0.2828\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 1.6855 - val_loss: 0.2660\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 1.5478 - val_loss: 0.2413\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 1.7706 - val_loss: 0.2356\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 1.7135 - val_loss: 0.2736\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 1.5580 - val_loss: 0.2727\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 1.6288 - val_loss: 0.2351\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 2.1563 - val_loss: 0.2686\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 1.7526 - val_loss: 0.3164\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 1.4940 - val_loss: 0.3122\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 1.7806 - val_loss: 0.1995\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 1.6173 - val_loss: 0.1963\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 1.7949 - val_loss: 0.1801\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 1.6444 - val_loss: 0.1757\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 1.5960 - val_loss: 0.1760\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 1s 104ms/step - loss: 1.4262 - val_loss: 0.1576\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 1s 103ms/step - loss: 1.5176 - val_loss: 0.1905\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 1.7102 - val_loss: 0.2438\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 1.5132 - val_loss: 0.1507\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 1s 105ms/step - loss: 1.6436 - val_loss: 0.1399\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 1s 102ms/step - loss: 1.6638 - val_loss: 0.1589\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 1.5810 - val_loss: 0.1326\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 1.7922 - val_loss: 0.1190\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 1.3895 - val_loss: 0.1473\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 1.4069 - val_loss: 0.1675\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 1.8231 - val_loss: 0.1142\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 1.4482 - val_loss: 0.1294\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 1.5574 - val_loss: 0.1157\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 1s 103ms/step - loss: 1.4569 - val_loss: 0.1247\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 1.2941 - val_loss: 0.1360\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 1.2474 - val_loss: 0.1242\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 1.3292 - val_loss: 0.1238\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 1s 102ms/step - loss: 1.4068 - val_loss: 0.1215\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 1s 103ms/step - loss: 1.5401 - val_loss: 0.1879\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 1.3690 - val_loss: 0.1333\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 1s 103ms/step - loss: 1.2851 - val_loss: 0.1220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9e15dc83b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 469: DatepartRegression\n",
            "Model Number: 470 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 471 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 472 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 473 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 474 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 475 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 476 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 477 with model MultivariateRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 478 with model NVAR in generation 3 of 10\n",
            "Model Number: 479 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 480 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 481 with model NVAR in generation 3 of 10\n",
            "Model Number: 482 with model GLM in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 482: GLM\n",
            "Model Number: 483 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 484 with model Theta in generation 3 of 10\n",
            "Model Number: 485 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 486 with model MultivariateRegression in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 486: MultivariateRegression\n",
            "Model Number: 487 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 488 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 489 with model WindowRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 489: WindowRegression\n",
            "Model Number: 490 with model SeasonalNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 490: SeasonalNaive\n",
            "Model Number: 491 with model Theta in generation 3 of 10\n",
            "Model Number: 492 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 493 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 494 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 495 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 496 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 497 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 498 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 499 with model LastValueNaive in generation 3 of 10\n",
            "New Generation: 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 500 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 501 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 502 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 503 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 504 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 505 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 506 with model SeasonalNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 507 with model FBProphet in generation 4 of 10\n",
            "Model Number: 508 with model GLS in generation 4 of 10\n",
            "Model Number: 509 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 510 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 511 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 512 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 513 with model WindowRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 513: WindowRegression\n",
            "Model Number: 514 with model DatepartRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 515 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 516 with model ETS in generation 4 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 517 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 518 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 519 with model GLS in generation 4 of 10\n",
            "Model Number: 520 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 521 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 522 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 523 with model WindowRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 523: WindowRegression\n",
            "Model Number: 524 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 525 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 526 with model DatepartRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+00, tolerance: 5.308e-03\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_regression.py:470: UserWarning:\n",
            "\n",
            "One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 526: DatepartRegression\n",
            "Model Number: 527 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 527: MultivariateRegression\n",
            "Model Number: 528 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 529 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 530 with model Theta in generation 4 of 10\n",
            "Model Number: 531 with model GLS in generation 4 of 10\n",
            "Model Number: 532 with model UnobservedComponents in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 532: UnobservedComponents\n",
            "Model Number: 533 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 534 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "14/14 [==============================] - 6s 15ms/step - loss: 0.9794\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.9624\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.9445\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.9287\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.9145\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.8983\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.8866\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.8713\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.8580\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.8461\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.8312\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.8174\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.8050\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.7933\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.7791\n",
            "Epoch 16/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.7675\n",
            "Epoch 17/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.7531\n",
            "Epoch 18/50\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.7409\n",
            "Epoch 19/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.7282\n",
            "Epoch 20/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.7177\n",
            "Epoch 21/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.7038\n",
            "Epoch 22/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.6908\n",
            "Epoch 23/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.6792\n",
            "Epoch 24/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.6669\n",
            "Epoch 25/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.6526\n",
            "Epoch 26/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.6397\n",
            "Epoch 27/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.6293\n",
            "Epoch 28/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.6184\n",
            "Epoch 29/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.6060\n",
            "Epoch 30/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.5960\n",
            "Epoch 31/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.5834\n",
            "Epoch 32/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.5710\n",
            "Epoch 33/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.5610\n",
            "Epoch 34/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.5472\n",
            "Epoch 35/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.5380\n",
            "Epoch 36/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.5260\n",
            "Epoch 37/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.5143\n",
            "Epoch 38/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.5062\n",
            "Epoch 39/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.4934\n",
            "Epoch 40/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.4841\n",
            "Epoch 41/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.4697\n",
            "Epoch 42/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.4616\n",
            "Epoch 43/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.4529\n",
            "Epoch 44/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.4424\n",
            "Epoch 45/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.4333\n",
            "Epoch 46/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.4234\n",
            "Epoch 47/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.4115\n",
            "Epoch 48/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.4032\n",
            "Epoch 49/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.3946\n",
            "Epoch 50/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.3825\n",
            "Model Number: 535 with model WindowRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 535: WindowRegression\n",
            "Model Number: 536 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 537 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 538 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 539 with model Theta in generation 4 of 10\n",
            "Model Number: 540 with model Theta in generation 4 of 10\n",
            "Model Number: 541 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 542 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 543 with model MultivariateMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 544 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 545 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 546 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 547 with model MultivariateMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 548 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 549 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 549: MultivariateRegression\n",
            "Model Number: 550 with model ETS in generation 4 of 10\n",
            "Model Number: 551 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 552 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 553 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 554 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 555 with model Theta in generation 4 of 10\n",
            "Model Number: 556 with model GLS in generation 4 of 10\n",
            "Model Number: 557 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 558 with model DatepartRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 558: DatepartRegression\n",
            "Model Number: 559 with model DatepartRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 560 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 561 with model UnobservedComponents in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 562 with model FBProphet in generation 4 of 10\n",
            "Model Number: 563 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 564 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 565 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 566 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 567 with model Theta in generation 4 of 10\n",
            "Model Number: 568 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 569 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 570 with model SectionalMotif in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 570: SectionalMotif\n",
            "Model Number: 571 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 572 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 573 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 574 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 575 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 576 with model SectionalMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 577 with model FBProphet in generation 4 of 10\n",
            "Model Number: 578 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 578: MultivariateRegression\n",
            "Model Number: 579 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 580 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 581 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 582 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 583 with model AverageValueNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 584 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 585 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 586 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 587 with model NVAR in generation 4 of 10\n",
            "Model Number: 588 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 589 with model NVAR in generation 4 of 10\n",
            "Model Number: 590 with model ETS in generation 4 of 10\n",
            "Model Number: 591 with model GLS in generation 4 of 10\n",
            "Model Number: 592 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 593 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 594 with model ETS in generation 4 of 10\n",
            "Model Number: 595 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 596 with model Theta in generation 4 of 10\n",
            "Model Number: 597 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 598 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 599 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 600 with model ETS in generation 4 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 601 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 602 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 603 with model LastValueNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning:\n",
            "\n",
            "Feature names only support names that are all strings. Got feature names with dtypes: ['Timestamp', 'str']. An error will be raised in 1.2.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:461: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:462: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning:\n",
            "\n",
            "Feature names only support names that are all strings. Got feature names with dtypes: ['Timestamp', 'str']. An error will be raised in 1.2.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 604 with model WindowRegression in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer MinMaxScaler failed on fit') in model 604: WindowRegression\n",
            "Model Number: 605 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 606 with model GLS in generation 4 of 10\n",
            "Model Number: 607 with model DatepartRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 608 with model SeasonalNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    1.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 609 with model FBProphet in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 609: FBProphet\n",
            "New Generation: 5 of 10\n",
            "Model Number: 610 with model MultivariateRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 611 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 612 with model Theta in generation 5 of 10\n",
            "Model Number: 613 with model AverageValueNaive in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 613: AverageValueNaive\n",
            "Model Number: 614 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 615 with model GLS in generation 5 of 10\n",
            "Model Number: 616 with model MultivariateRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 617 with model FBProphet in generation 5 of 10\n",
            "Model Number: 618 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 619 with model GLS in generation 5 of 10\n",
            "Model Number: 620 with model MultivariateRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 621 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 622 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 623 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 624 with model NVAR in generation 5 of 10\n",
            "Model Number: 625 with model GLS in generation 5 of 10\n",
            "Model Number: 626 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 627 with model Theta in generation 5 of 10\n",
            "Model Number: 628 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 629 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 630 with model ETS in generation 5 of 10\n",
            "Model Number: 631 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 632 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 633 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 634 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 635 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 636 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 637 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 638 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 639 with model ETS in generation 5 of 10\n",
            "Model Number: 640 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 641 with model SeasonalNaive in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 642 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 643 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 644 with model SeasonalNaive in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 645 with model Theta in generation 5 of 10\n",
            "Model Number: 646 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 647 with model ETS in generation 5 of 10\n",
            "Model Number: 648 with model DatepartRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 649 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 650 with model Theta in generation 5 of 10\n",
            "Model Number: 651 with model DatepartRegression in generation 5 of 10\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 195ms/step - loss: 28861132257099776.0000 - val_loss: 794872617369600.0000\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 31126038163488768.0000 - val_loss: 72248111136768.0000\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 31385494990356480.0000 - val_loss: 1050731134058496.0000\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 31662859683364864.0000 - val_loss: 1771963651457024.0000\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 32321136435920896.0000 - val_loss: 1735607424385024.0000\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 28770486972317696.0000 - val_loss: 1453971789053952.0000\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 28213099001544704.0000 - val_loss: 1031441429299200.0000\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 30202038226780160.0000 - val_loss: 87311995895808.0000\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 25828475176747008.0000 - val_loss: 844241387388928.0000\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 29498462454153216.0000 - val_loss: 1680534669361152.0000\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 29056783049818112.0000 - val_loss: 2465503427690496.0000\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 31929783310876672.0000 - val_loss: 2620240630382592.0000\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 651: DatepartRegression\n",
            "Model Number: 652 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 653 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 654 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 655 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 656 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 657 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 658 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 659 with model MultivariateRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 660 with model ETS in generation 5 of 10\n",
            "Model Number: 661 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 662 with model AverageValueNaive in generation 5 of 10\n",
            "Template Eval Error: ValueError('Model AverageValueNaive returned NaN for one or more series. fail_on_forecast_nan=True') in model 662: AverageValueNaive\n",
            "Model Number: 663 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 664 with model GLS in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/percentile.py:47: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 665 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 666 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 667 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 668 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 669 with model GLS in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 670 with model FBProphet in generation 5 of 10\n",
            "Model Number: 671 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 672 with model DatepartRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 673 with model AverageValueNaive in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 673: AverageValueNaive\n",
            "Model Number: 674 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 675 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 676 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 677 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 678 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 679 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 680 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 681 with model MultivariateMotif in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 682 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 683 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 684 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 685 with model WindowRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 686 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 687 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 688 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 689 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 690 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 691 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 692 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 693 with model UnobservedComponents in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 694 with model Theta in generation 5 of 10\n",
            "Model Number: 695 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 696 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 697 with model MultivariateMotif in generation 5 of 10\n",
            "New Generation: 6 of 10\n",
            "Model Number: 698 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 699 with model MultivariateRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 700 with model UnivariateRegression in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 700: UnivariateRegression\n",
            "Model Number: 701 with model MultivariateRegression in generation 6 of 10\n",
            "Template Eval Error: XGBoostError('[11:55:35] /workspace/src/objective/regression_obj.cu:243: PoissonRegression: label must be nonnegative\\nStack trace:\\n  [bt] (0) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f9e04db0cb4]\\n  [bt] (1) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::obj::PoissonRegression::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*)+0x785) [0x7f9e04fbdaf5]\\n  [bt] (2) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x345) [0x7f9e04e4a505]\\n  [bt] (3) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7f9e04dadaa5]\\n  [bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f9f24370dae]\\n  [bt] (5) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7f9f2437071f]\\n  [bt] (6) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xd849) [0x7f9f24580849]\\n  [bt] (7) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xdeaf) [0x7f9f24580eaf]\\n  [bt] (8) /usr/bin/python3(_PyObject_FastCallKeywords+0x562) [0x594b72]\\n\\n') in model 701: MultivariateRegression\n",
            "Model Number: 702 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 703 with model Theta in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 704 with model GLS in generation 6 of 10\n",
            "Model Number: 705 with model NVAR in generation 6 of 10\n",
            "Model Number: 706 with model ETS in generation 6 of 10\n",
            "Model Number: 707 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 708 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 709 with model MultivariateMotif in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 710 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 711 with model GLS in generation 6 of 10\n",
            "Model Number: 712 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 713 with model UnivariateMotif in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 714 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 715 with model Theta in generation 6 of 10\n",
            "Model Number: 716 with model Theta in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 717 with model ETS in generation 6 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 718 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 719 with model AverageValueNaive in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 719: AverageValueNaive\n",
            "Model Number: 720 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 721 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 722 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 723 with model ETS in generation 6 of 10\n",
            "Model Number: 724 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 725 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 726 with model MultivariateMotif in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1120: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/percentile.py:47: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError('Model MultivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 726: MultivariateMotif\n",
            "Model Number: 727 with model WindowRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 727: WindowRegression\n",
            "Model Number: 728 with model UnivariateMotif in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 729 with model GLM in generation 6 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 729: GLM\n",
            "Model Number: 730 with model DatepartRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 731 with model DatepartRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 731: DatepartRegression\n",
            "Model Number: 732 with model UnivariateMotif in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 733 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 734 with model MultivariateRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 735 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 736 with model SeasonalNaive in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 737 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 738 with model GLS in generation 6 of 10\n",
            "Model Number: 739 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 740 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 741 with model SectionalMotif in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 741: SectionalMotif\n",
            "Model Number: 742 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 743 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 744 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 745 with model DatepartRegression in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 745: DatepartRegression\n",
            "Model Number: 746 with model DatepartRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:84: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 747 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 748 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 749 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 750 with model Theta in generation 6 of 10\n",
            "Model Number: 751 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 752 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 753 with model DatepartRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 754 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 755 with model UnobservedComponents in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 755: UnobservedComponents\n",
            "Model Number: 756 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 757 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 758 with model UnivariateMotif in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 759 with model MultivariateRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 760 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 761 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 762 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 763 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 764 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 765 with model GLS in generation 6 of 10\n",
            "Model Number: 766 with model Theta in generation 6 of 10\n",
            "Model Number: 767 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 768 with model GLS in generation 6 of 10\n",
            "Model Number: 769 with model WindowRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 769: WindowRegression\n",
            "Model Number: 770 with model NVAR in generation 6 of 10\n",
            "Model Number: 771 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 772 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 773 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 774 with model LastValueNaive in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 775 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 776 with model FBProphet in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 776: FBProphet\n",
            "Model Number: 777 with model MultivariateRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 778 with model FBProphet in generation 6 of 10\n",
            "Model Number: 779 with model DatepartRegression in generation 6 of 10\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 5s 15ms/step - loss: 0.9999\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9995\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.9999\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9993\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0009\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9981\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9987\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0005\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9992\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.0004\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9995\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9977\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9987\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9993\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9985\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0018\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9973\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9986\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0004\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9996\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9978\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0050\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9995\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9973\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9976\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9990\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0024\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9961\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0005\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0002\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0019\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9956\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0030\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0041\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0000\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0010\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0028\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0027\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9983\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9960\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9980\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0020\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0067\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9980\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9948\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0040\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9983\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9964\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9973\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9974\n",
            "Model Number: 780 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 781 with model Theta in generation 6 of 10\n",
            "Model Number: 782 with model WindowRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 782: WindowRegression\n",
            "Model Number: 783 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 784 with model UnobservedComponents in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 784: UnobservedComponents\n",
            "Model Number: 785 with model MultivariateMotif in generation 6 of 10\n",
            "New Generation: 7 of 10\n",
            "Model Number: 786 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 787 with model NVAR in generation 7 of 10\n",
            "Model Number: 788 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 789 with model UnivariateMotif in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 789: UnivariateMotif\n",
            "Model Number: 790 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 790: DatepartRegression\n",
            "Model Number: 791 with model ETS in generation 7 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 792 with model SeasonalNaive in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:3253: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:3253: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_regression.py:470: UserWarning:\n",
            "\n",
            "One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 793 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 794 with model MultivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 795 with model MultivariateMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 796 with model DatepartRegression in generation 7 of 10\n",
            "Epoch 1/750\n",
            "5/5 [==============================] - 6s 7ms/step - loss: 0.3331\n",
            "Epoch 2/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3242\n",
            "Epoch 3/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3096\n",
            "Epoch 4/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3029\n",
            "Epoch 5/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2925\n",
            "Epoch 6/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2729\n",
            "Epoch 7/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2690\n",
            "Epoch 8/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2581\n",
            "Epoch 9/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2555\n",
            "Epoch 10/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2502\n",
            "Epoch 11/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2364\n",
            "Epoch 12/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2361\n",
            "Epoch 13/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2358\n",
            "Epoch 14/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2242\n",
            "Epoch 15/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2146\n",
            "Epoch 16/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2567\n",
            "Epoch 17/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2195\n",
            "Epoch 18/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2183\n",
            "Epoch 19/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2134\n",
            "Epoch 20/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2101\n",
            "Epoch 21/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2115\n",
            "Epoch 22/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2138\n",
            "Epoch 23/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2012\n",
            "Epoch 24/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2147\n",
            "Epoch 25/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2191\n",
            "Epoch 26/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2097\n",
            "Epoch 27/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2075\n",
            "Epoch 28/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2095\n",
            "Epoch 29/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2075\n",
            "Epoch 30/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2249\n",
            "Epoch 31/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2211\n",
            "Epoch 32/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2207\n",
            "Epoch 33/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2111\n",
            "Epoch 34/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2004\n",
            "Epoch 35/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2212\n",
            "Epoch 36/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2012\n",
            "Epoch 37/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2021\n",
            "Epoch 38/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2237\n",
            "Epoch 39/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2019\n",
            "Epoch 40/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2174\n",
            "Epoch 41/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2028\n",
            "Epoch 42/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1987\n",
            "Epoch 43/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1998\n",
            "Epoch 44/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1937\n",
            "Epoch 45/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1916\n",
            "Epoch 46/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2002\n",
            "Epoch 47/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1926\n",
            "Epoch 48/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2151\n",
            "Epoch 49/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2148\n",
            "Epoch 50/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2146\n",
            "Epoch 51/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2084\n",
            "Epoch 52/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1947\n",
            "Epoch 53/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2190\n",
            "Epoch 54/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2063\n",
            "Epoch 55/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2053\n",
            "Epoch 56/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1845\n",
            "Epoch 57/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2064\n",
            "Epoch 58/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2028\n",
            "Epoch 59/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1982\n",
            "Epoch 60/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2059\n",
            "Epoch 61/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1870\n",
            "Epoch 62/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2049\n",
            "Epoch 63/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2032\n",
            "Epoch 64/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1978\n",
            "Epoch 65/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1950\n",
            "Epoch 66/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1849\n",
            "Epoch 67/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1930\n",
            "Epoch 68/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1913\n",
            "Epoch 69/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1814\n",
            "Epoch 70/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1838\n",
            "Epoch 71/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2163\n",
            "Epoch 72/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2066\n",
            "Epoch 73/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1936\n",
            "Epoch 74/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2003\n",
            "Epoch 75/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1937\n",
            "Epoch 76/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2118\n",
            "Epoch 77/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1967\n",
            "Epoch 78/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2054\n",
            "Epoch 79/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2116\n",
            "Epoch 80/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1857\n",
            "Epoch 81/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2019\n",
            "Epoch 82/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1983\n",
            "Epoch 83/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1851\n",
            "Epoch 84/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1827\n",
            "Epoch 85/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1995\n",
            "Epoch 86/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1958\n",
            "Epoch 87/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2083\n",
            "Epoch 88/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1947\n",
            "Epoch 89/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1953\n",
            "Epoch 90/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2017\n",
            "Epoch 91/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1906\n",
            "Epoch 92/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1865\n",
            "Epoch 93/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1936\n",
            "Epoch 94/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1812\n",
            "Epoch 95/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1921\n",
            "Epoch 96/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2136\n",
            "Epoch 97/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1922\n",
            "Epoch 98/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1907\n",
            "Epoch 99/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1812\n",
            "Epoch 100/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1892\n",
            "Epoch 101/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2083\n",
            "Epoch 102/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2008\n",
            "Epoch 103/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2014\n",
            "Epoch 104/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2028\n",
            "Epoch 105/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1892\n",
            "Epoch 106/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2013\n",
            "Epoch 107/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1946\n",
            "Epoch 108/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1937\n",
            "Epoch 109/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1987\n",
            "Epoch 110/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1912\n",
            "Epoch 111/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1849\n",
            "Epoch 112/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2055\n",
            "Epoch 113/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1877\n",
            "Epoch 114/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1961\n",
            "Epoch 115/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2000\n",
            "Epoch 116/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1970\n",
            "Epoch 117/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1952\n",
            "Epoch 118/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1746\n",
            "Epoch 119/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1811\n",
            "Epoch 120/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1908\n",
            "Epoch 121/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1676\n",
            "Epoch 122/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1952\n",
            "Epoch 123/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1692\n",
            "Epoch 124/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2112\n",
            "Epoch 125/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1889\n",
            "Epoch 126/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1719\n",
            "Epoch 127/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1931\n",
            "Epoch 128/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1801\n",
            "Epoch 129/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1935\n",
            "Epoch 130/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1971\n",
            "Epoch 131/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1818\n",
            "Epoch 132/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1916\n",
            "Epoch 133/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1951\n",
            "Epoch 134/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1706\n",
            "Epoch 135/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1749\n",
            "Epoch 136/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1837\n",
            "Epoch 137/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1856\n",
            "Epoch 138/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2034\n",
            "Epoch 139/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1891\n",
            "Epoch 140/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1886\n",
            "Epoch 141/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2000\n",
            "Epoch 142/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1868\n",
            "Epoch 143/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1928\n",
            "Epoch 144/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1811\n",
            "Epoch 145/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1762\n",
            "Epoch 146/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1672\n",
            "Epoch 147/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1941\n",
            "Epoch 148/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1827\n",
            "Epoch 149/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1817\n",
            "Epoch 150/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1674\n",
            "Epoch 151/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1921\n",
            "Epoch 152/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1926\n",
            "Epoch 153/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1915\n",
            "Epoch 154/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1764\n",
            "Epoch 155/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1907\n",
            "Epoch 156/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1785\n",
            "Epoch 157/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1969\n",
            "Epoch 158/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1855\n",
            "Epoch 159/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1754\n",
            "Epoch 160/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1803\n",
            "Epoch 161/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2020\n",
            "Epoch 162/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1698\n",
            "Epoch 163/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1855\n",
            "Epoch 164/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1883\n",
            "Epoch 165/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1879\n",
            "Epoch 166/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2006\n",
            "Epoch 167/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1867\n",
            "Epoch 168/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1911\n",
            "Epoch 169/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1674\n",
            "Epoch 170/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1861\n",
            "Epoch 171/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1939\n",
            "Epoch 172/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1868\n",
            "Epoch 173/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1986\n",
            "Epoch 174/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1820\n",
            "Epoch 175/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1857\n",
            "Epoch 176/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1857\n",
            "Epoch 177/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1808\n",
            "Epoch 178/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2054\n",
            "Epoch 179/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1727\n",
            "Epoch 180/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1752\n",
            "Epoch 181/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1910\n",
            "Epoch 182/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1644\n",
            "Epoch 183/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1873\n",
            "Epoch 184/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1938\n",
            "Epoch 185/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1818\n",
            "Epoch 186/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1832\n",
            "Epoch 187/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1954\n",
            "Epoch 188/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1885\n",
            "Epoch 189/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1812\n",
            "Epoch 190/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1792\n",
            "Epoch 191/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1858\n",
            "Epoch 192/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1774\n",
            "Epoch 193/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1720\n",
            "Epoch 194/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1944\n",
            "Epoch 195/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1799\n",
            "Epoch 196/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1882\n",
            "Epoch 197/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2012\n",
            "Epoch 198/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2024\n",
            "Epoch 199/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1999\n",
            "Epoch 200/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1894\n",
            "Epoch 201/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1829\n",
            "Epoch 202/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1621\n",
            "Epoch 203/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1730\n",
            "Epoch 204/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1745\n",
            "Epoch 205/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1776\n",
            "Epoch 206/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1709\n",
            "Epoch 207/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1800\n",
            "Epoch 208/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2145\n",
            "Epoch 209/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1853\n",
            "Epoch 210/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1719\n",
            "Epoch 211/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1807\n",
            "Epoch 212/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1910\n",
            "Epoch 213/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1657\n",
            "Epoch 214/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1762\n",
            "Epoch 215/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1905\n",
            "Epoch 216/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1854\n",
            "Epoch 217/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1702\n",
            "Epoch 218/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1669\n",
            "Epoch 219/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1775\n",
            "Epoch 220/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1840\n",
            "Epoch 221/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1696\n",
            "Epoch 222/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1815\n",
            "Epoch 223/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1676\n",
            "Epoch 224/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1846\n",
            "Epoch 225/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1873\n",
            "Epoch 226/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1849\n",
            "Epoch 227/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1897\n",
            "Epoch 228/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1865\n",
            "Epoch 229/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1928\n",
            "Epoch 230/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1788\n",
            "Epoch 231/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1665\n",
            "Epoch 232/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1961\n",
            "Epoch 233/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1818\n",
            "Epoch 234/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1758\n",
            "Epoch 235/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1734\n",
            "Epoch 236/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1893\n",
            "Epoch 237/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1804\n",
            "Epoch 238/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1781\n",
            "Epoch 239/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1673\n",
            "Epoch 240/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1791\n",
            "Epoch 241/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1828\n",
            "Epoch 242/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1664\n",
            "Epoch 243/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1787\n",
            "Epoch 244/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1920\n",
            "Epoch 245/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1714\n",
            "Epoch 246/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2013\n",
            "Epoch 247/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1776\n",
            "Epoch 248/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1774\n",
            "Epoch 249/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1946\n",
            "Epoch 250/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1660\n",
            "Epoch 251/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1671\n",
            "Epoch 252/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1718\n",
            "Epoch 253/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1785\n",
            "Epoch 254/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1629\n",
            "Epoch 255/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1498\n",
            "Epoch 256/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2067\n",
            "Epoch 257/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1789\n",
            "Epoch 258/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1601\n",
            "Epoch 259/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1526\n",
            "Epoch 260/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1802\n",
            "Epoch 261/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1742\n",
            "Epoch 262/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2064\n",
            "Epoch 263/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1858\n",
            "Epoch 264/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2029\n",
            "Epoch 265/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1883\n",
            "Epoch 266/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1648\n",
            "Epoch 267/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1681\n",
            "Epoch 268/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1678\n",
            "Epoch 269/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1731\n",
            "Epoch 270/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1601\n",
            "Epoch 271/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1619\n",
            "Epoch 272/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1926\n",
            "Epoch 273/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1678\n",
            "Epoch 274/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1639\n",
            "Epoch 275/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1719\n",
            "Epoch 276/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1972\n",
            "Epoch 277/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1671\n",
            "Epoch 278/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1761\n",
            "Epoch 279/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1835\n",
            "Epoch 280/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1811\n",
            "Epoch 281/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1646\n",
            "Epoch 282/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1631\n",
            "Epoch 283/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1943\n",
            "Epoch 284/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1910\n",
            "Epoch 285/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1943\n",
            "Epoch 286/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1945\n",
            "Epoch 287/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1714\n",
            "Epoch 288/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1752\n",
            "Epoch 289/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2013\n",
            "Epoch 290/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1853\n",
            "Epoch 291/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1843\n",
            "Epoch 292/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1717\n",
            "Epoch 293/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1895\n",
            "Epoch 294/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1779\n",
            "Epoch 295/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1702\n",
            "Epoch 296/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1640\n",
            "Epoch 297/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1882\n",
            "Epoch 298/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1751\n",
            "Epoch 299/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1615\n",
            "Epoch 300/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1621\n",
            "Epoch 301/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1714\n",
            "Epoch 302/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1851\n",
            "Epoch 303/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1680\n",
            "Epoch 304/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1590\n",
            "Epoch 305/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1837\n",
            "Epoch 306/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1722\n",
            "Epoch 307/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1676\n",
            "Epoch 308/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1708\n",
            "Epoch 309/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1739\n",
            "Epoch 310/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1677\n",
            "Epoch 311/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1831\n",
            "Epoch 312/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1771\n",
            "Epoch 313/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1582\n",
            "Epoch 314/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1726\n",
            "Epoch 315/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1660\n",
            "Epoch 316/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1669\n",
            "Epoch 317/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1852\n",
            "Epoch 318/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1771\n",
            "Epoch 319/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1709\n",
            "Epoch 320/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1772\n",
            "Epoch 321/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1855\n",
            "Epoch 322/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1678\n",
            "Epoch 323/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1697\n",
            "Epoch 324/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1859\n",
            "Epoch 325/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1831\n",
            "Epoch 326/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1725\n",
            "Epoch 327/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1746\n",
            "Epoch 328/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1607\n",
            "Epoch 329/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1554\n",
            "Epoch 330/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1810\n",
            "Epoch 331/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1698\n",
            "Epoch 332/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1613\n",
            "Epoch 333/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1655\n",
            "Epoch 334/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1720\n",
            "Epoch 335/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2103\n",
            "Epoch 336/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1775\n",
            "Epoch 337/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1658\n",
            "Epoch 338/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1652\n",
            "Epoch 339/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1781\n",
            "Epoch 340/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1911\n",
            "Epoch 341/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1791\n",
            "Epoch 342/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1781\n",
            "Epoch 343/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1727\n",
            "Epoch 344/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1786\n",
            "Epoch 345/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1789\n",
            "Epoch 346/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1733\n",
            "Epoch 347/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1646\n",
            "Epoch 348/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1589\n",
            "Epoch 349/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1608\n",
            "Epoch 350/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1855\n",
            "Epoch 351/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1971\n",
            "Epoch 352/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1679\n",
            "Epoch 353/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1720\n",
            "Epoch 354/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1630\n",
            "Epoch 355/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1548\n",
            "Epoch 356/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1687\n",
            "Epoch 357/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1979\n",
            "Epoch 358/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1642\n",
            "Epoch 359/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1699\n",
            "Epoch 360/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1673\n",
            "Epoch 361/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1619\n",
            "Epoch 362/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1540\n",
            "Epoch 363/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1701\n",
            "Epoch 364/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1822\n",
            "Epoch 365/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1741\n",
            "Epoch 366/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1690\n",
            "Epoch 367/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1563\n",
            "Epoch 368/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1671\n",
            "Epoch 369/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1774\n",
            "Epoch 370/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1848\n",
            "Epoch 371/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1769\n",
            "Epoch 372/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1682\n",
            "Epoch 373/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1675\n",
            "Epoch 374/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1777\n",
            "Epoch 375/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1643\n",
            "Epoch 376/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1768\n",
            "Epoch 377/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1515\n",
            "Epoch 378/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1508\n",
            "Epoch 379/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1684\n",
            "Epoch 380/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1859\n",
            "Epoch 381/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1701\n",
            "Epoch 382/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1704\n",
            "Epoch 383/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1798\n",
            "Epoch 384/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1592\n",
            "Epoch 385/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1505\n",
            "Epoch 386/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1529\n",
            "Epoch 387/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1592\n",
            "Epoch 388/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1743\n",
            "Epoch 389/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1783\n",
            "Epoch 390/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1702\n",
            "Epoch 391/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1637\n",
            "Epoch 392/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1708\n",
            "Epoch 393/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1619\n",
            "Epoch 394/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1822\n",
            "Epoch 395/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1782\n",
            "Epoch 396/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1867\n",
            "Epoch 397/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1511\n",
            "Epoch 398/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1738\n",
            "Epoch 399/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1772\n",
            "Epoch 400/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1685\n",
            "Epoch 401/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1839\n",
            "Epoch 402/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1575\n",
            "Epoch 403/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1731\n",
            "Epoch 404/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1782\n",
            "Epoch 405/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1695\n",
            "Epoch 406/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1726\n",
            "Epoch 407/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1517\n",
            "Epoch 408/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1808\n",
            "Epoch 409/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2038\n",
            "Epoch 410/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1788\n",
            "Epoch 411/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1591\n",
            "Epoch 412/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1532\n",
            "Epoch 413/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1944\n",
            "Epoch 414/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1571\n",
            "Epoch 415/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1667\n",
            "Epoch 416/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1602\n",
            "Epoch 417/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1389\n",
            "Epoch 418/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1365\n",
            "Epoch 419/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1638\n",
            "Epoch 420/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1460\n",
            "Epoch 421/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1849\n",
            "Epoch 422/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1663\n",
            "Epoch 423/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1500\n",
            "Epoch 424/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1521\n",
            "Epoch 425/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1535\n",
            "Epoch 426/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1707\n",
            "Epoch 427/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1803\n",
            "Epoch 428/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1931\n",
            "Epoch 429/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1753\n",
            "Epoch 430/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1533\n",
            "Epoch 431/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1724\n",
            "Epoch 432/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1553\n",
            "Epoch 433/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1719\n",
            "Epoch 434/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1637\n",
            "Epoch 435/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1393\n",
            "Epoch 436/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1925\n",
            "Epoch 437/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1623\n",
            "Epoch 438/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1752\n",
            "Epoch 439/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1501\n",
            "Epoch 440/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1875\n",
            "Epoch 441/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1907\n",
            "Epoch 442/750\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1505\n",
            "Epoch 443/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1747\n",
            "Epoch 444/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1768\n",
            "Epoch 445/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1717\n",
            "Epoch 446/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1838\n",
            "Epoch 447/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1462\n",
            "Epoch 448/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1520\n",
            "Epoch 449/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1814\n",
            "Epoch 450/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1696\n",
            "Epoch 451/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1908\n",
            "Epoch 452/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1497\n",
            "Epoch 453/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1704\n",
            "Epoch 454/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1608\n",
            "Epoch 455/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1592\n",
            "Epoch 456/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1659\n",
            "Epoch 457/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1661\n",
            "Epoch 458/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1936\n",
            "Epoch 459/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1799\n",
            "Epoch 460/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1702\n",
            "Epoch 461/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1572\n",
            "Epoch 462/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1698\n",
            "Epoch 463/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1613\n",
            "Epoch 464/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1707\n",
            "Epoch 465/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1513\n",
            "Epoch 466/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1837\n",
            "Epoch 467/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1782\n",
            "Epoch 468/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1700\n",
            "Epoch 469/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1682\n",
            "Epoch 470/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1660\n",
            "Epoch 471/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1685\n",
            "Epoch 472/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1486\n",
            "Epoch 473/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1730\n",
            "Epoch 474/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1721\n",
            "Epoch 475/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1850\n",
            "Epoch 476/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1502\n",
            "Epoch 477/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1569\n",
            "Epoch 478/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1609\n",
            "Epoch 479/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1753\n",
            "Epoch 480/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1736\n",
            "Epoch 481/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1910\n",
            "Epoch 482/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1563\n",
            "Epoch 483/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1671\n",
            "Epoch 484/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1593\n",
            "Epoch 485/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1654\n",
            "Epoch 486/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1714\n",
            "Epoch 487/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1624\n",
            "Epoch 488/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1520\n",
            "Epoch 489/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1696\n",
            "Epoch 490/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2107\n",
            "Epoch 491/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1812\n",
            "Epoch 492/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1742\n",
            "Epoch 493/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1562\n",
            "Epoch 494/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1801\n",
            "Epoch 495/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1577\n",
            "Epoch 496/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1896\n",
            "Epoch 497/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1776\n",
            "Epoch 498/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1417\n",
            "Epoch 499/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1785\n",
            "Epoch 500/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1571\n",
            "Epoch 501/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1370\n",
            "Epoch 502/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1706\n",
            "Epoch 503/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1439\n",
            "Epoch 504/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1610\n",
            "Epoch 505/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1792\n",
            "Epoch 506/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1569\n",
            "Epoch 507/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1496\n",
            "Epoch 508/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1583\n",
            "Epoch 509/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1365\n",
            "Epoch 510/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1727\n",
            "Epoch 511/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1806\n",
            "Epoch 512/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1755\n",
            "Epoch 513/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1521\n",
            "Epoch 514/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1787\n",
            "Epoch 515/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1558\n",
            "Epoch 516/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2091\n",
            "Epoch 517/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1496\n",
            "Epoch 518/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1686\n",
            "Epoch 519/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1549\n",
            "Epoch 520/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1426\n",
            "Epoch 521/750\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1865\n",
            "Epoch 522/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1584\n",
            "Epoch 523/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1380\n",
            "Epoch 524/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2084\n",
            "Epoch 525/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1501\n",
            "Epoch 526/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1787\n",
            "Epoch 527/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1706\n",
            "Epoch 528/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1716\n",
            "Epoch 529/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1744\n",
            "Epoch 530/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1444\n",
            "Epoch 531/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1782\n",
            "Epoch 532/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1660\n",
            "Epoch 533/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1965\n",
            "Epoch 534/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1384\n",
            "Epoch 535/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1425\n",
            "Epoch 536/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1528\n",
            "Epoch 537/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1710\n",
            "Epoch 538/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1643\n",
            "Epoch 539/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1588\n",
            "Epoch 540/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1762\n",
            "Epoch 541/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1827\n",
            "Epoch 542/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1513\n",
            "Epoch 543/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1745\n",
            "Epoch 544/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1765\n",
            "Epoch 545/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1729\n",
            "Epoch 546/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1553\n",
            "Epoch 547/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1637\n",
            "Epoch 548/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1741\n",
            "Epoch 549/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1720\n",
            "Epoch 550/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1684\n",
            "Epoch 551/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1603\n",
            "Epoch 552/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1697\n",
            "Epoch 553/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1961\n",
            "Epoch 554/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1562\n",
            "Epoch 555/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1522\n",
            "Epoch 556/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1554\n",
            "Epoch 557/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1685\n",
            "Epoch 558/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1681\n",
            "Epoch 559/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1554\n",
            "Epoch 560/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1433\n",
            "Epoch 561/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1905\n",
            "Epoch 562/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1721\n",
            "Epoch 563/750\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1887\n",
            "Epoch 564/750\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.1864\n",
            "Epoch 565/750\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1865\n",
            "Epoch 566/750\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1649\n",
            "Epoch 567/750\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1696\n",
            "Epoch 568/750\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1780\n",
            "Epoch 569/750\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1450\n",
            "Epoch 570/750\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1563\n",
            "Epoch 571/750\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1641\n",
            "Epoch 572/750\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1767\n",
            "Epoch 573/750\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1389\n",
            "Epoch 574/750\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1689\n",
            "Epoch 575/750\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1455\n",
            "Epoch 576/750\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1553\n",
            "Epoch 577/750\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1652\n",
            "Epoch 578/750\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1797\n",
            "Epoch 579/750\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1851\n",
            "Epoch 580/750\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1746\n",
            "Epoch 581/750\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1830\n",
            "Epoch 582/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1509\n",
            "Epoch 583/750\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1640\n",
            "Epoch 584/750\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1707\n",
            "Epoch 585/750\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1562\n",
            "Epoch 586/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1499\n",
            "Epoch 587/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1826\n",
            "Epoch 588/750\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1876\n",
            "Epoch 589/750\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1667\n",
            "Epoch 590/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1848\n",
            "Epoch 591/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1996\n",
            "Epoch 592/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1709\n",
            "Epoch 593/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1616\n",
            "Epoch 594/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1709\n",
            "Epoch 595/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1749\n",
            "Epoch 596/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1500\n",
            "Epoch 597/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1600\n",
            "Epoch 598/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1670\n",
            "Epoch 599/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1599\n",
            "Epoch 600/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1610\n",
            "Epoch 601/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1500\n",
            "Epoch 602/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1969\n",
            "Epoch 603/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1644\n",
            "Epoch 604/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1718\n",
            "Epoch 605/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1723\n",
            "Epoch 606/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1633\n",
            "Epoch 607/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1916\n",
            "Epoch 608/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1710\n",
            "Epoch 609/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1636\n",
            "Epoch 610/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1492\n",
            "Epoch 611/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1867\n",
            "Epoch 612/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1600\n",
            "Epoch 613/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1911\n",
            "Epoch 614/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1718\n",
            "Epoch 615/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1734\n",
            "Epoch 616/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1497\n",
            "Epoch 617/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1418\n",
            "Epoch 618/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1659\n",
            "Epoch 619/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1642\n",
            "Epoch 620/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1523\n",
            "Epoch 621/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1765\n",
            "Epoch 622/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1557\n",
            "Epoch 623/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1393\n",
            "Epoch 624/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1833\n",
            "Epoch 625/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1876\n",
            "Epoch 626/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1481\n",
            "Epoch 627/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1636\n",
            "Epoch 628/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1642\n",
            "Epoch 629/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1681\n",
            "Epoch 630/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1964\n",
            "Epoch 631/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1956\n",
            "Epoch 632/750\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1662\n",
            "Epoch 633/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1437\n",
            "Epoch 634/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1615\n",
            "Epoch 635/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1796\n",
            "Epoch 636/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1781\n",
            "Epoch 637/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1571\n",
            "Epoch 638/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1821\n",
            "Epoch 639/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1823\n",
            "Epoch 640/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1569\n",
            "Epoch 641/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1517\n",
            "Epoch 642/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1727\n",
            "Epoch 643/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1573\n",
            "Epoch 644/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1650\n",
            "Epoch 645/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1619\n",
            "Epoch 646/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1468\n",
            "Epoch 647/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1830\n",
            "Epoch 648/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1731\n",
            "Epoch 649/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1830\n",
            "Epoch 650/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1519\n",
            "Epoch 651/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1766\n",
            "Epoch 652/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1439\n",
            "Epoch 653/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1828\n",
            "Epoch 654/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1608\n",
            "Epoch 655/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1752\n",
            "Epoch 656/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1620\n",
            "Epoch 657/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1410\n",
            "Epoch 658/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1492\n",
            "Epoch 659/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1556\n",
            "Epoch 660/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1715\n",
            "Epoch 661/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1467\n",
            "Epoch 662/750\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1673\n",
            "Epoch 663/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1466\n",
            "Epoch 664/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1777\n",
            "Epoch 665/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1548\n",
            "Epoch 666/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1852\n",
            "Epoch 667/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1588\n",
            "Epoch 668/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1842\n",
            "Epoch 669/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1463\n",
            "Epoch 670/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1652\n",
            "Epoch 671/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1642\n",
            "Epoch 672/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1800\n",
            "Epoch 673/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1558\n",
            "Epoch 674/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1201\n",
            "Epoch 675/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1745\n",
            "Epoch 676/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1635\n",
            "Epoch 677/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1544\n",
            "Epoch 678/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1303\n",
            "Epoch 679/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1538\n",
            "Epoch 680/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1795\n",
            "Epoch 681/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1582\n",
            "Epoch 682/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1928\n",
            "Epoch 683/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1667\n",
            "Epoch 684/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1594\n",
            "Epoch 685/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1695\n",
            "Epoch 686/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1525\n",
            "Epoch 687/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1454\n",
            "Epoch 688/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1618\n",
            "Epoch 689/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1828\n",
            "Epoch 690/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1631\n",
            "Epoch 691/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1492\n",
            "Epoch 692/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1477\n",
            "Epoch 693/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1782\n",
            "Epoch 694/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1772\n",
            "Epoch 695/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1625\n",
            "Epoch 696/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1553\n",
            "Epoch 697/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1784\n",
            "Epoch 698/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1551\n",
            "Epoch 699/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1536\n",
            "Epoch 700/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1614\n",
            "Epoch 701/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1363\n",
            "Epoch 702/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1654\n",
            "Epoch 703/750\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1570\n",
            "Epoch 704/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1531\n",
            "Epoch 705/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1694\n",
            "Epoch 706/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1779\n",
            "Epoch 707/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1462\n",
            "Epoch 708/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1627\n",
            "Epoch 709/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1413\n",
            "Epoch 710/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1563\n",
            "Epoch 711/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1621\n",
            "Epoch 712/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1591\n",
            "Epoch 713/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1564\n",
            "Epoch 714/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1555\n",
            "Epoch 715/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1907\n",
            "Epoch 716/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1506\n",
            "Epoch 717/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1526\n",
            "Epoch 718/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1352\n",
            "Epoch 719/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1759\n",
            "Epoch 720/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1676\n",
            "Epoch 721/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1803\n",
            "Epoch 722/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1583\n",
            "Epoch 723/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1458\n",
            "Epoch 724/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1419\n",
            "Epoch 725/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1447\n",
            "Epoch 726/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1577\n",
            "Epoch 727/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1547\n",
            "Epoch 728/750\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1570\n",
            "Epoch 729/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1778\n",
            "Epoch 730/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1692\n",
            "Epoch 731/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1660\n",
            "Epoch 732/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1636\n",
            "Epoch 733/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1272\n",
            "Epoch 734/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1493\n",
            "Epoch 735/750\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1725\n",
            "Epoch 736/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1508\n",
            "Epoch 737/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1472\n",
            "Epoch 738/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1392\n",
            "Epoch 739/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1465\n",
            "Epoch 740/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1716\n",
            "Epoch 741/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1371\n",
            "Epoch 742/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1873\n",
            "Epoch 743/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1484\n",
            "Epoch 744/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1390\n",
            "Epoch 745/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1518\n",
            "Epoch 746/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1541\n",
            "Epoch 747/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1960\n",
            "Epoch 748/750\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1467\n",
            "Epoch 749/750\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1516\n",
            "Epoch 750/750\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1482\n",
            "Model Number: 797 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 798 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 799 with model WindowRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 800 with model GLS in generation 7 of 10\n",
            "Model Number: 801 with model Theta in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 801: Theta\n",
            "Model Number: 802 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 803 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 804 with model MultivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 805 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 806 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 807 with model MultivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 808 with model DatepartRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 809 with model MultivariateMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 810 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 811 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 812 with model DatepartRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 813 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 814 with model UnivariateRegression in generation 7 of 10\n",
            "Model Number: 815 with model GLS in generation 7 of 10\n",
            "Model Number: 816 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 817 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 818 with model UnivariateMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 819 with model NVAR in generation 7 of 10\n",
            "Model Number: 820 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 821 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 822 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 823 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 823: MultivariateRegression\n",
            "Model Number: 824 with model SectionalMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 825 with model FBProphet in generation 7 of 10\n",
            "Model Number: 826 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 827 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 828 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 829 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 830 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 831 with model DatepartRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 832 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 833 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 834 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 835 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 836 with model DatepartRegression in generation 7 of 10\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 8s 282ms/step - loss: 42366377746497536.0000 - val_loss: 4318761951690752.0000\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 27252551040630784.0000 - val_loss: 483115571085312.0000\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 25416955032764416.0000 - val_loss: 8566322472419328.0000\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 25510568139948032.0000 - val_loss: 1313742314799104.0000\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 1s 126ms/step - loss: 23540709306925056.0000 - val_loss: 2195217646092288.0000\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 20644926391844864.0000 - val_loss: 5414874649722880.0000\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 23348043516477440.0000 - val_loss: 2544929452589056.0000\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 21820504037916672.0000 - val_loss: 61777299636224.0000\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 21540162932572160.0000 - val_loss: 12904260379344896.0000\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 28053463657086976.0000 - val_loss: 837609152577536.0000\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 107ms/step - loss: 23987272089075712.0000 - val_loss: 702974611423232.0000\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 107ms/step - loss: 20626569701621760.0000 - val_loss: 353326088585216.0000\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 103ms/step - loss: 21549738562158592.0000 - val_loss: 6682027977867264.0000\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 22089830699630592.0000 - val_loss: 5545988726980608.0000\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 19771989321318400.0000 - val_loss: 2527811860430848.0000\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 20800114297667584.0000 - val_loss: 1425850222247936.0000\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 20674931033374720.0000 - val_loss: 6146043439742976.0000\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 20261355747540992.0000 - val_loss: 2814697153757184.0000\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 836: DatepartRegression\n",
            "Model Number: 837 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 838 with model ETS in generation 7 of 10\n",
            "Model Number: 839 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 840 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 841 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 842 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 843 with model ETS in generation 7 of 10\n",
            "Model Number: 844 with model UnivariateMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 845 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 846 with model MultivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 847 with model Theta in generation 7 of 10\n",
            "Model Number: 848 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 848: DatepartRegression\n",
            "Model Number: 849 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 850 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 851 with model ETS in generation 7 of 10\n",
            "Model Number: 852 with model GLS in generation 7 of 10\n",
            "Model Number: 853 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 854 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 855 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 856 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 857 with model Theta in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 857: Theta\n",
            "Model Number: 858 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 859 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 860 with model Theta in generation 7 of 10\n",
            "Model Number: 861 with model NVAR in generation 7 of 10\n",
            "Model Number: 862 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 863 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 864 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 865 with model WindowRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 866 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 867 with model ETS in generation 7 of 10\n",
            "Model Number: 868 with model WindowRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 6s 9ms/step - loss: 141.8327\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 118.1464\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 133.7872\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 118.1984\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 116.2269\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 122.9248\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 101.6780\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 107.4506\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 101.1796\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 121.8709\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 108.0427\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 103.5208\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 101.6120\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 102.8159\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 106.2190\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 104.2375\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 102.5970\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 102.8147\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 117.3401\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 110.5537\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 109.0719\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 122.0582\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 114.3147\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 122.1856\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 112.3567\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 157.6214\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 112.7378\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 123.0108\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 101.8167\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 127.3970\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 107.3324\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 131.9971\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 125.4617\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 111.6377\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 108.1176\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 110.7904\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 100.4074\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 102.4493\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 101.0933\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.7820\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.0856\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 105.2902\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 106.6963\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 105.8659\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 99.6718\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 99.3335\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 108.6230\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 111.4074\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 112.2726\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 115.1064\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 110.4903\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 106.4984\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 104.2290\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 100.7601\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 108.5177\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 115.1853\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 101.4592\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 103.3885\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.3036\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 109.3812\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 122.4345\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 113.3577\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 123.6972\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 102.1663\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 101.1070\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.0366\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 100.5880\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 103.9146\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.6566\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 107.6357\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 103.6641\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 105.1290\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 110.1030\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 118.4635\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 109.0117\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 108.8143\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.3018\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 104.6409\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 102.1206\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 102.5069\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 112.2319\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 100.4720\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 117.2837\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 107.7300\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 124.5996\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 110.4361\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 98.0127\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 105.8824\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 99.9212\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 102.6586\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 100.1876\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 102.0236\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 100.1251\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 105.1340\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 100.5739\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 115.4523\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 104.2811\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 103.8857\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 100.0133\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 107.5938\n",
            "Model Number: 869 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 870 with model SeasonalNaive in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 871 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 872 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 873 with model WindowRegression in generation 7 of 10\n",
            "New Generation: 8 of 10\n",
            "Model Number: 874 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 875 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 876 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 877 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 878 with model FBProphet in generation 8 of 10\n",
            "Model Number: 879 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 880 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 881 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 882 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 883 with model UnivariateRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 883: UnivariateRegression\n",
            "Model Number: 884 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 885 with model FBProphet in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 885: FBProphet\n",
            "Model Number: 886 with model DatepartRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 72075.96470325728, tolerance: 976.341293069307\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 887 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 888 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 889 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 890 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 891 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 892 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 892: DatepartRegression\n",
            "Model Number: 893 with model LastValueNaive in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 894 with model SeasonalNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 894: SeasonalNaive\n",
            "Model Number: 895 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 896 with model Theta in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 896: Theta\n",
            "Model Number: 897 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 898 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2683: RuntimeWarning:\n",
            "\n",
            "Degrees of freedom <= 0 for slice\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2683: RuntimeWarning:\n",
            "\n",
            "Degrees of freedom <= 0 for slice\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 898: MultivariateRegression\n",
            "Model Number: 899 with model UnobservedComponents in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 900 with model FBProphet in generation 8 of 10\n",
            "Model Number: 901 with model ETS in generation 8 of 10\n",
            "Model Number: 902 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 903 with model Theta in generation 8 of 10\n",
            "Model Number: 904 with model SeasonalNaive in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 905 with model WindowRegression in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 905: WindowRegression\n",
            "Model Number: 906 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 907 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 908 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 909 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 910 with model UnivariateRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 910: UnivariateRegression\n",
            "Model Number: 911 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 912 with model MultivariateMotif in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 913 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 914 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 915 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 916 with model Theta in generation 8 of 10\n",
            "Model Number: 917 with model GLS in generation 8 of 10\n",
            "Model Number: 918 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 919 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 920 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 921 with model Theta in generation 8 of 10\n",
            "Model Number: 922 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 923 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 924 with model Theta in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 925 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 926 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 927 with model ETS in generation 8 of 10\n",
            "Model Number: 928 with model DatepartRegression in generation 8 of 10\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 7s 204ms/step - loss: 1199.3978 - val_loss: 3802.9700\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1195.0088 - val_loss: 3800.3401\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1182.6871 - val_loss: 3797.6655\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1183.2111 - val_loss: 3795.4324\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1184.5597 - val_loss: 3793.1750\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1183.7747 - val_loss: 3791.2620\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1185.7495 - val_loss: 3789.7505\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1189.6438 - val_loss: 3787.5410\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1179.1453 - val_loss: 3784.7998\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1179.0933 - val_loss: 3782.3311\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1176.5616 - val_loss: 3780.1689\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1175.1238 - val_loss: 3778.2583\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1171.4342 - val_loss: 3775.6917\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1179.7057 - val_loss: 3773.1465\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1172.9846 - val_loss: 3770.5156\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1170.1047 - val_loss: 3768.3340\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1170.0186 - val_loss: 3765.7437\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1170.3451 - val_loss: 3763.0527\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1171.6589 - val_loss: 3760.8418\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1159.7833 - val_loss: 3757.9700\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1157.7325 - val_loss: 3755.0779\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1161.7010 - val_loss: 3753.2520\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1156.1460 - val_loss: 3750.1077\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1161.4469 - val_loss: 3747.7534\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1163.3488 - val_loss: 3746.0676\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1150.7064 - val_loss: 3744.6716\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1158.1956 - val_loss: 3742.3403\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1158.4984 - val_loss: 3739.8381\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1158.3955 - val_loss: 3737.4958\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1149.1158 - val_loss: 3734.8293\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1147.7136 - val_loss: 3732.3357\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1151.7665 - val_loss: 3728.7878\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1142.6438 - val_loss: 3726.2190\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1140.1178 - val_loss: 3723.3787\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1147.0046 - val_loss: 3720.9380\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1140.0654 - val_loss: 3719.1047\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1131.9467 - val_loss: 3715.3784\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1138.6003 - val_loss: 3712.1082\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1139.8601 - val_loss: 3709.8579\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1130.2329 - val_loss: 3706.6975\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1144.5852 - val_loss: 3703.0547\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1129.9913 - val_loss: 3700.1831\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1132.2324 - val_loss: 3697.5598\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1119.2145 - val_loss: 3694.5569\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1128.3137 - val_loss: 3691.1692\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1110.3813 - val_loss: 3687.5986\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1116.2528 - val_loss: 3683.7083\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1113.6061 - val_loss: 3680.4797\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1111.6556 - val_loss: 3677.7346\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1112.4409 - val_loss: 3674.2839\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1120.0145 - val_loss: 3670.3613\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1105.7355 - val_loss: 3666.0420\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1111.9200 - val_loss: 3662.9766\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1112.4904 - val_loss: 3659.9575\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1106.3979 - val_loss: 3656.7917\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1108.8870 - val_loss: 3653.4729\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1098.7264 - val_loss: 3649.5093\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1105.5284 - val_loss: 3646.7546\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1094.3303 - val_loss: 3642.9724\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1098.3090 - val_loss: 3639.5811\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1086.0474 - val_loss: 3635.4338\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1084.3210 - val_loss: 3632.8879\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1090.5752 - val_loss: 3630.1091\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1080.8339 - val_loss: 3626.2864\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1082.0831 - val_loss: 3623.0903\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1083.5325 - val_loss: 3619.7668\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1074.9980 - val_loss: 3616.3213\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1083.2203 - val_loss: 3612.9294\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1079.0497 - val_loss: 3607.9187\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1076.7013 - val_loss: 3604.5562\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1075.0430 - val_loss: 3600.2998\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1082.0984 - val_loss: 3595.9236\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1070.6113 - val_loss: 3591.1750\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1065.7906 - val_loss: 3587.0833\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1056.3740 - val_loss: 3582.6345\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1046.0278 - val_loss: 3579.2278\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1061.9315 - val_loss: 3574.7197\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1064.3542 - val_loss: 3569.1006\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1055.8240 - val_loss: 3565.6567\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1049.1370 - val_loss: 3562.7395\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1051.1538 - val_loss: 3558.7815\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1041.9684 - val_loss: 3553.7126\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1058.9823 - val_loss: 3550.0442\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1054.4232 - val_loss: 3546.7107\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1049.1182 - val_loss: 3543.2019\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1046.9110 - val_loss: 3538.0010\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1037.9629 - val_loss: 3534.1953\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1034.4026 - val_loss: 3529.3970\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1041.4893 - val_loss: 3525.2747\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1027.8164 - val_loss: 3520.7002\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1034.0465 - val_loss: 3516.4731\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1034.1842 - val_loss: 3510.9045\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1030.9286 - val_loss: 3504.2847\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1026.8987 - val_loss: 3499.5801\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1014.6156 - val_loss: 3495.1365\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1017.4308 - val_loss: 3489.6375\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1017.4911 - val_loss: 3484.5378\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1019.8616 - val_loss: 3479.3328\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1014.7445 - val_loss: 3475.7634\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1020.8600 - val_loss: 3472.0188\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 928: DatepartRegression\n",
            "Model Number: 929 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 930 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 931 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 932 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 933 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 934 with model GLS in generation 8 of 10\n",
            "Model Number: 935 with model GLS in generation 8 of 10\n",
            "Model Number: 936 with model Theta in generation 8 of 10\n",
            "Model Number: 937 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 938 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 938: DatepartRegression\n",
            "Model Number: 939 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 940 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 941 with model UnobservedComponents in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 942 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 943 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 944 with model UnivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 945 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 946 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 947 with model ETS in generation 8 of 10\n",
            "Model Number: 948 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 949 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 950 with model UnobservedComponents in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 950: UnobservedComponents\n",
            "Model Number: 951 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 952 with model ETS in generation 8 of 10\n",
            "Model Number: 953 with model ConstantNaive in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 954 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 955 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 956 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 957 with model WindowRegression in generation 8 of 10\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 5s 8ms/step - loss: 544.1295\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1189.6416\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 712.8531\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 226.9026\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 197.4395\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 230.3749\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 127.5898\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 219.4494\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 343.0977\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 138.9380\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 741.4438\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 697.8595\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 409.6507\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 227.2987\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 112.3611\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 341.4933\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 195.9548\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 424.4642\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 966.7049\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 913.2059\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 547.5626\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 130.7090\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 215.1820\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 369.9350\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 246.3392\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 154.3387\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 131.9545\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 195.0173\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 148.8502\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 192.6897\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 231.5058\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 134.2834\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 521.7582\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 562.0489\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 416.9817\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 207.9534\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 209.4257\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 212.4796\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 153.3679\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 284.5614\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 190.7638\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 196.5431\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 183.7029\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 168.8826\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 243.6164\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 354.7220\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 251.1569\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 167.7656\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 159.6395\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 140.8480\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 129.0622\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 353.7889\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 236.1952\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 178.2421\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 130.5479\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 353.3713\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 179.6453\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 150.6745\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 449.4032\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 560.1132\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 259.4753\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 209.4445\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 195.2971\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 260.3530\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 122.4209\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 229.9590\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 179.4546\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 154.1665\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 135.0917\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 200.0478\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 141.3701\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 185.5374\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 170.4566\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 322.7270\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 252.6902\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 243.6333\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 164.3830\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 210.5117\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 159.6931\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 277.5917\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 170.6046\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 203.7922\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 201.1263\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 215.6586\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 124.5439\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 295.2231\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 288.9829\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 188.8507\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 193.1952\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 313.7267\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 262.4149\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 196.9338\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 216.2632\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 146.9210\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 130.7272\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 245.7104\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 157.9025\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 189.2249\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 214.0307\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 158.8349\n",
            "Model Number: 958 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 959 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 960 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 961 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Generation: 9 of 10\n",
            "Model Number: 962 with model Theta in generation 9 of 10\n",
            "Model Number: 963 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 964 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 965 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 966 with model SectionalMotif in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 967 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 968 with model ETS in generation 9 of 10\n",
            "Model Number: 969 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 970 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 971 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 972 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 973 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 974 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 975 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 975: DatepartRegression\n",
            "Model Number: 976 with model GLS in generation 9 of 10\n",
            "Model Number: 977 with model WindowRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 978 with model FBProphet in generation 9 of 10\n",
            "Model Number: 979 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 980 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 981 with model DatepartRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 982 with model GLS in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 983 with model ETS in generation 9 of 10\n",
            "Model Number: 984 with model DatepartRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 985 with model GLS in generation 9 of 10\n",
            "Model Number: 986 with model NVAR in generation 9 of 10\n",
            "Model Number: 987 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 988 with model ETS in generation 9 of 10\n",
            "Model Number: 989 with model ETS in generation 9 of 10\n",
            "Model Number: 990 with model GLS in generation 9 of 10\n",
            "Model Number: 991 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 992 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 993 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 994 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 995 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 995: DatepartRegression\n",
            "Model Number: 996 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 997 with model MultivariateRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 998 with model WindowRegression in generation 9 of 10\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 5s 8ms/step - loss: 99.6774\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 98.7060\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 97.5671\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 96.1133\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 94.2124\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 91.7821\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 88.5572\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 83.9473\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 76.9002\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 67.1445\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 54.2302\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 36.3459\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 19.2486\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 17.7897\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20.4019\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 15.5446\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 14.0623\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.1903\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 14.5646\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.7687\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 14.3195\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 14.4094\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 13.0734\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.9417\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 12.6774\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 13.3102\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 12.4652\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 13.0621\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.1821\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 13.1999\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.4845\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 13.5641\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 12.5485\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 10.8527\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.5697\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.3727\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.3656\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 11.7389\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 13.5576\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.4973\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.6423\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.5051\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.3527\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.0298\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.7721\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.5171\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 11.6598\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 12.2895\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 11.1400\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 12.0482\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 11.6154\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11.1789\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11.6508\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 11.2093\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.0678\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11.3158\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10.8559\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 11.6829\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11.0655\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 10.8889\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 10.4800\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 11.2429\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 11.1531\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 10.8355\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 10.6469\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11.8138\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 10.6455\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 9.7311\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 11.5700\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 10.3086\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 10.8532\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 10.3736\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10.2875\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 10.9775\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 10.7709\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10.4764\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 10.9209\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10.5452\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.8912\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.8272\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.8167\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10.3677\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.9591\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 10.1527\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.8548\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10.1879\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10.5471\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10.2792\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 10.2034\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.9674\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 9.7106\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 9.9965\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 9.9337\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.6144\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 9.5361\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.8520\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 10.1582\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.3670\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10.3912\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10.1895\n",
            "Model Number: 999 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1000 with model ETS in generation 9 of 10\n",
            "Model Number: 1001 with model NVAR in generation 9 of 10\n",
            "Model Number: 1002 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1003 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1004 with model UnivariateMotif in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1004: UnivariateMotif\n",
            "Model Number: 1005 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1006 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1007 with model DatepartRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1008 with model Theta in generation 9 of 10\n",
            "Model Number: 1009 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1010 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1010: DatepartRegression\n",
            "Model Number: 1011 with model MultivariateRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1012 with model WindowRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1013 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1014 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1015 with model UnivariateMotif in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1016 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1017 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1018 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1019 with model MultivariateRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1020 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1021 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1022 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1023 with model LastValueNaive in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1024 with model FBProphet in generation 9 of 10\n",
            "Model Number: 1025 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1026 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1027 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1028 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1029 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1030 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1031 with model DatepartRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1032 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1033 with model WindowRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1034 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1035 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1036 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1037 with model UnivariateRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1037: UnivariateRegression\n",
            "Model Number: 1038 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1039 with model MultivariateRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1040 with model UnobservedComponents in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1041 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1042 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1043 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1044 with model MultivariateRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 1044: MultivariateRegression\n",
            "Model Number: 1045 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1046 with model Theta in generation 9 of 10\n",
            "Model Number: 1047 with model GLS in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1048 with model FBProphet in generation 9 of 10\n",
            "Model Number: 1049 with model MultivariateMotif in generation 9 of 10\n",
            "New Generation: 10 of 10\n",
            "Model Number: 1050 with model ETS in generation 10 of 10\n",
            "Model Number: 1051 with model GLS in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1051: GLS\n",
            "Model Number: 1052 with model DatepartRegression in generation 10 of 10\n",
            "Model Number: 1053 with model GLS in generation 10 of 10\n",
            "Model Number: 1054 with model UnobservedComponents in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 1054: UnobservedComponents\n",
            "Model Number: 1055 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1056 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1057 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1058 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1059 with model MultivariateRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1060 with model DatepartRegression in generation 10 of 10\n",
            "Model Number: 1061 with model MultivariateRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1062 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1063 with model WindowRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1064 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1065 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1066 with model SeasonalNaive in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1067 with model Theta in generation 10 of 10\n",
            "Model Number: 1068 with model DatepartRegression in generation 10 of 10\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 3s 124ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 1068: DatepartRegression\n",
            "Model Number: 1069 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1070 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1071 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1072 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1073 with model MultivariateRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 1073: MultivariateRegression\n",
            "Model Number: 1074 with model Theta in generation 10 of 10\n",
            "Model Number: 1075 with model DatepartRegression in generation 10 of 10\n",
            "Model Number: 1076 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1077 with model MultivariateMotif in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1078 with model UnobservedComponents in generation 10 of 10\n",
            "Model Number: 1079 with model MultivariateRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1080 with model MultivariateMotif in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1081 with model DatepartRegression in generation 10 of 10\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 6s 8ms/step - loss: 0.3098\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3089\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3129\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3033\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3073\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3051\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3082\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2992\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3078\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3086\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3001\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3052\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3037\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3016\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3050\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3029\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3015\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3066\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3052\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3029\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3046\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3039\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3067\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3029\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3035\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3066\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3059\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3084\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3021\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3014\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3040\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3056\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3008\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3023\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3057\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3046\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3039\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3012\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3037\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3004\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3051\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3043\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3045\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3053\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3038\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3037\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3045\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3034\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3019\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3017\n",
            "Model Number: 1082 with model DatepartRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1083 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1084 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1085 with model WindowRegression in generation 10 of 10\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 5s 8ms/step - loss: 18093.3848\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 15183.6934\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 8011.5117\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3337.5168\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2984.1589\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3741.9487\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4372.1030\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2141.1589\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1854.1011\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2994.3618\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4093.9604\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1834.2576\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2528.5120\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5228.7803\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 6612.7480\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 8049.0444\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10078.1221\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5060.5776\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1825.8347\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2184.3718\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3823.9744\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 7842.5688\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 8620.1748\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5981.0498\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 17581.8105\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 8385.6367\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 22726.8848\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 8169.1826\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 11534.0586\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5032.5693\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1290.9130\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3531.2097\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3785.3179\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10279.9092\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4266.1479\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3668.0664\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4928.2715\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 6958.2012\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 10272.4844\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5129.6284\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2957.7869\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1405.5474\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 6235.6055\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4587.2075\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5221.2036\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12576.1689\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 6653.4736\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4652.6431\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 7070.1079\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3413.2683\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1522.1992\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 8046.6890\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 6632.3770\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 6528.7793\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4780.3545\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3641.6724\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 11567.2988\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3612.4670\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1050.7745\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1175.5048\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1803.4701\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1494.9619\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1480.8839\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2727.3901\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 9886.3037\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5517.0947\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 11952.4229\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4845.4995\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2804.5212\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1859.1522\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1339.5089\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2324.9248\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 8861.5293\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 6644.7007\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4231.8208\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11657.6553\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4976.1079\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5359.5386\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3211.1240\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1889.6803\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2139.3518\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1164.8887\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 936.6069\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1884.6438\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2220.1975\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4266.8340\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5162.8018\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2325.0730\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1663.2830\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2372.2861\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2950.2603\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4057.4443\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3920.6758\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3632.0012\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5173.0098\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3058.2456\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3926.3503\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 6049.5503\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2771.9656\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2702.3440\n",
            "Model Number: 1086 with model DatepartRegression in generation 10 of 10\n",
            "Model Number: 1087 with model UnobservedComponents in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 1087: UnobservedComponents\n",
            "Model Number: 1088 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1089 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1090 with model DatepartRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 1090: DatepartRegression\n",
            "Model Number: 1091 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1092 with model MultivariateRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_regression.py:470: UserWarning:\n",
            "\n",
            "One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1093 with model Theta in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1094 with model Theta in generation 10 of 10\n",
            "Model Number: 1095 with model UnivariateRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 1095: UnivariateRegression\n",
            "Model Number: 1096 with model ETS in generation 10 of 10\n",
            "Model Number: 1097 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1098 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1099 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1100 with model MultivariateRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1101 with model ETS in generation 10 of 10\n",
            "Model Number: 1102 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1103 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1104 with model GLS in generation 10 of 10\n",
            "Model Number: 1105 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1106 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1107 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1108 with model DatepartRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1109 with model UnivariateMotif in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1110 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1111 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1112 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1113 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1114 with model UnobservedComponents in generation 10 of 10\n",
            "Model Number: 1115 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1116 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 72075.96470325728, tolerance: 976.341293069307\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1117 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 72075.96470325728, tolerance: 976.341293069307\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1118 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 72075.96470325728, tolerance: 976.341293069307\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1119 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 72075.96470325728, tolerance: 976.341293069307\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1120 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 72075.96470325728, tolerance: 976.341293069307\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1121 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 72075.96470325728, tolerance: 976.341293069307\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1122 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1123 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Round: 1\n",
            "Model Number: 1 of 162 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 39807.87874045735, tolerance: 681.7954292134833\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ˆ 1 - Ensemble with avg smape 4.12: \n",
            "Model Number: 2 of 162 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 39807.87874045735, tolerance: 681.7954292134833\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ˆ 2 - Ensemble with avg smape 3.87: \n",
            "Model Number: 3 of 162 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 39807.87874045735, tolerance: 681.7954292134833\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ˆ 3 - Ensemble with avg smape 2.79: \n",
            "Model Number: 4 of 162 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 39807.87874045735, tolerance: 681.7954292134833\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 - Ensemble with avg smape 4.86: \n",
            "Model Number: 5 of 162 with model WindowRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 39807.87874045735, tolerance: 681.7954292134833\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 - WindowRegression with avg smape 4.57: \n",
            "Model Number: 6 of 162 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 39807.87874045735, tolerance: 681.7954292134833\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 - Ensemble with avg smape 4.61: \n",
            "Model Number: 7 of 162 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 39807.87874045735, tolerance: 681.7954292134833\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 - Ensemble with avg smape 4.05: \n",
            "Model Number: 8 of 162 with model WindowRegression for Validation 1\n",
            "8 - WindowRegression with avg smape 7.07: \n",
            "Model Number: 9 of 162 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 - Ensemble with avg smape 4.48: \n",
            "Model Number: 10 of 162 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 - Ensemble with avg smape 4.42: \n",
            "Model Number: 11 of 162 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 - DatepartRegression with avg smape 4.26: \n",
            "Model Number: 12 of 162 with model MultivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 - MultivariateMotif with avg smape 4.6: \n",
            "Model Number: 13 of 162 with model WindowRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 5s 8ms/step - loss: 121.3156\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 121.7051\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 100.4174\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 131.2839\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 111.6774\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 113.3877\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 102.4788\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 108.0412\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 108.8937\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 104.2245\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 110.5112\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 104.1024\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 100.7204\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 103.3032\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 102.0985\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 98.8218\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 105.1097\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 99.8764\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 103.5380\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 103.5713\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 109.6971\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 96.8760\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 115.4720\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 101.2314\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 103.2396\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.6850\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 100.1703\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 99.3742\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 104.1994\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 105.2307\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 103.6114\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 100.7097\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 99.9495\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 97.7261\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 104.9006\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 102.8961\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 106.7335\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 104.2060\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 110.6119\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 103.7051\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 108.5584\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 112.0703\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 100.7403\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 112.1724\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 102.3599\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 109.7959\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 106.6712\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 105.9191\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 106.6732\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 107.7899\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 102.6657\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 102.0976\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 100.7576\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 111.4046\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 106.8137\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 109.5911\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 102.0511\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 107.7303\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 99.7952\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 104.1875\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 99.7463\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 105.0418\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 101.4932\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 104.1237\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 101.3282\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 103.3492\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 103.3319\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 99.1020\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 109.8455\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 101.6876\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 110.5391\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 102.1077\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 105.8307\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 98.6585\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 106.6685\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.0023\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 97.8657\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 99.8361\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 102.5392\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 98.8373\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 104.0982\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 103.4945\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 99.6108\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 100.1789\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 103.4948\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 96.3766\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 97.1869\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 102.6628\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 99.8840\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.9675\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 97.2060\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 97.5178\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 97.7339\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 96.3764\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 98.6371\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 100.6469\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 97.7558\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 109.9007\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 108.3954\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 97.8870\n",
            "13 - WindowRegression with avg smape 7.93: \n",
            "Model Number: 14 of 162 with model DatepartRegression for Validation 1\n",
            "14 - DatepartRegression with avg smape 4.51: \n",
            "Model Number: 15 of 162 with model WindowRegression for Validation 1\n",
            "15 - WindowRegression with avg smape 3.65: \n",
            "Model Number: 16 of 162 with model UnivariateMotif for Validation 1\n",
            "16 - UnivariateMotif with avg smape 10.2: \n",
            "Model Number: 17 of 162 with model UnivariateMotif for Validation 1\n",
            "17 - UnivariateMotif with avg smape 10.2: \n",
            "Model Number: 18 of 162 with model UnivariateMotif for Validation 1\n",
            "18 - UnivariateMotif with avg smape 9.69: \n",
            "Model Number: 19 of 162 with model UnivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 - UnivariateMotif with avg smape 9.79: \n",
            "Model Number: 20 of 162 with model UnivariateMotif for Validation 1\n",
            "20 - UnivariateMotif with avg smape 11.67: \n",
            "Model Number: 21 of 162 with model WindowRegression for Validation 1\n",
            "21 - WindowRegression with avg smape 8.05: \n",
            "Model Number: 22 of 162 with model UnivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 - UnivariateMotif with avg smape 10.14: \n",
            "Model Number: 23 of 162 with model DatepartRegression for Validation 1\n",
            "23 - DatepartRegression with avg smape 4.89: \n",
            "Model Number: 24 of 162 with model MultivariateMotif for Validation 1\n",
            "24 - MultivariateMotif with avg smape 5.95: \n",
            "Model Number: 25 of 162 with model UnivariateMotif for Validation 1\n",
            "25 - UnivariateMotif with avg smape 6.82: \n",
            "Model Number: 26 of 162 with model WindowRegression for Validation 1\n",
            "26 - WindowRegression with avg smape 4.81: \n",
            "Model Number: 27 of 162 with model WindowRegression for Validation 1\n",
            "27 - WindowRegression with avg smape 4.81: \n",
            "Model Number: 28 of 162 with model WindowRegression for Validation 1\n",
            "28 - WindowRegression with avg smape 5.43: \n",
            "Model Number: 29 of 162 with model MultivariateMotif for Validation 1\n",
            "29 - MultivariateMotif with avg smape 8.61: \n",
            "Model Number: 30 of 162 with model WindowRegression for Validation 1\n",
            "30 - WindowRegression with avg smape 4.94: \n",
            "Model Number: 31 of 162 with model MultivariateMotif for Validation 1\n",
            "31 - MultivariateMotif with avg smape 4.5: \n",
            "Model Number: 32 of 162 with model MultivariateMotif for Validation 1\n",
            "32 - MultivariateMotif with avg smape 4.5: \n",
            "Model Number: 33 of 162 with model MultivariateMotif for Validation 1\n",
            "33 - MultivariateMotif with avg smape 9.83: \n",
            "Model Number: 34 of 162 with model DatepartRegression for Validation 1\n",
            "34 - DatepartRegression with avg smape 5.19: \n",
            "Model Number: 35 of 162 with model MultivariateMotif for Validation 1\n",
            "35 - MultivariateMotif with avg smape 7.37: \n",
            "Model Number: 36 of 162 with model UnivariateMotif for Validation 1\n",
            "36 - UnivariateMotif with avg smape 4.34: \n",
            "Model Number: 37 of 162 with model UnivariateMotif for Validation 1\n",
            "37 - UnivariateMotif with avg smape 4.34: \n",
            "Model Number: 38 of 162 with model SeasonalNaive for Validation 1\n",
            "38 - SeasonalNaive with avg smape 5.6: \n",
            "Model Number: 39 of 162 with model MultivariateMotif for Validation 1\n",
            "39 - MultivariateMotif with avg smape 5.39: \n",
            "Model Number: 40 of 162 with model MultivariateMotif for Validation 1\n",
            "40 - MultivariateMotif with avg smape 8.13: \n",
            "Model Number: 41 of 162 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41 - MultivariateRegression with avg smape 4.83: \n",
            "Model Number: 42 of 162 with model SeasonalNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42 - SeasonalNaive with avg smape 5.78: \n",
            "Model Number: 43 of 162 with model SeasonalNaive for Validation 1\n",
            "43 - SeasonalNaive with avg smape 5.78: \n",
            "Model Number: 44 of 162 with model SeasonalNaive for Validation 1\n",
            "44 - SeasonalNaive with avg smape 5.86: \n",
            "Model Number: 45 of 162 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 - MultivariateRegression with avg smape 8.81: \n",
            "Model Number: 46 of 162 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 - DatepartRegression with avg smape 4.64: \n",
            "Model Number: 47 of 162 with model UnivariateRegression for Validation 1\n",
            "47 - UnivariateRegression with avg smape 9.27: \n",
            "Model Number: 48 of 162 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 - DatepartRegression with avg smape 4.62: \n",
            "Model Number: 49 of 162 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 - MultivariateRegression with avg smape 7.12: \n",
            "Model Number: 50 of 162 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 - DatepartRegression with avg smape 4.61: \n",
            "Model Number: 51 of 162 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51 - DatepartRegression with avg smape 4.56: \n",
            "Model Number: 52 of 162 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52 - DatepartRegression with avg smape 4.61: \n",
            "Model Number: 53 of 162 with model MultivariateRegression for Validation 1\n",
            "53 - MultivariateRegression with avg smape 4.12: \n",
            "Model Number: 54 of 162 with model AverageValueNaive for Validation 1\n",
            "54 - AverageValueNaive with avg smape 4.11: \n",
            "Model Number: 55 of 162 with model SectionalMotif for Validation 1\n",
            "55 - SectionalMotif with avg smape 3.53: \n",
            "Model Number: 56 of 162 with model MultivariateRegression for Validation 1\n",
            "56 - MultivariateRegression with avg smape 4.32: \n",
            "Model Number: 57 of 162 with model MultivariateRegression for Validation 1\n",
            "57 - MultivariateRegression with avg smape 6.81: \n",
            "Model Number: 58 of 162 with model GLS for Validation 1\n",
            "58 - GLS with avg smape 5.28: \n",
            "Model Number: 59 of 162 with model MultivariateRegression for Validation 1\n",
            "59 - MultivariateRegression with avg smape 4.68: \n",
            "Model Number: 60 of 162 with model AverageValueNaive for Validation 1\n",
            "60 - AverageValueNaive with avg smape 4.56: \n",
            "Model Number: 61 of 162 with model SectionalMotif for Validation 1\n",
            "61 - SectionalMotif with avg smape 14.81: \n",
            "Model Number: 62 of 162 with model SeasonalNaive for Validation 1\n",
            "62 - SeasonalNaive with avg smape 5.5: \n",
            "Model Number: 63 of 162 with model MultivariateRegression for Validation 1\n",
            "63 - MultivariateRegression with avg smape 6.94: \n",
            "Model Number: 64 of 162 with model MultivariateRegression for Validation 1\n",
            "64 - MultivariateRegression with avg smape 6.44: \n",
            "Model Number: 65 of 162 with model AverageValueNaive for Validation 1\n",
            "65 - AverageValueNaive with avg smape 7.61: \n",
            "Model Number: 66 of 162 with model ETS for Validation 1\n",
            "66 - ETS with avg smape 11.82: \n",
            "Model Number: 67 of 162 with model ETS for Validation 1\n",
            "67 - ETS with avg smape 12.42: \n",
            "Model Number: 68 of 162 with model ETS for Validation 1\n",
            "68 - ETS with avg smape 12.42: \n",
            "Model Number: 69 of 162 with model UnivariateRegression for Validation 1\n",
            "69 - UnivariateRegression with avg smape 8.98: \n",
            "Model Number: 70 of 162 with model UnobservedComponents for Validation 1\n",
            "70 - UnobservedComponents with avg smape 10.95: \n",
            "Model Number: 71 of 162 with model UnobservedComponents for Validation 1\n",
            "71 - UnobservedComponents with avg smape 11.12: \n",
            "Model Number: 72 of 162 with model SeasonalNaive for Validation 1\n",
            "72 - SeasonalNaive with avg smape 6.37: \n",
            "Model Number: 73 of 162 with model SeasonalNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 - SeasonalNaive with avg smape 6.27: \n",
            "Model Number: 74 of 162 with model SeasonalNaive for Validation 1\n",
            "74 - SeasonalNaive with avg smape 6.27: \n",
            "Model Number: 75 of 162 with model SeasonalNaive for Validation 1\n",
            "75 - SeasonalNaive with avg smape 6.37: \n",
            "Model Number: 76 of 162 with model ETS for Validation 1\n",
            "76 - ETS with avg smape 10.47: \n",
            "Model Number: 77 of 162 with model LastValueNaive for Validation 1\n",
            "77 - LastValueNaive with avg smape 9.76: \n",
            "Model Number: 78 of 162 with model UnivariateRegression for Validation 1\n",
            "78 - UnivariateRegression with avg smape 10.78: \n",
            "Model Number: 79 of 162 with model ETS for Validation 1\n",
            "79 - ETS with avg smape 11.95: \n",
            "Model Number: 80 of 162 with model ETS for Validation 1\n",
            "80 - ETS with avg smape 11.95: \n",
            "Model Number: 81 of 162 with model LastValueNaive for Validation 1\n",
            "81 - LastValueNaive with avg smape 10.12: \n",
            "Model Number: 82 of 162 with model ETS for Validation 1\n",
            "82 - ETS with avg smape 12.91: \n",
            "Model Number: 83 of 162 with model ETS for Validation 1\n",
            "83 - ETS with avg smape 12.88: \n",
            "Model Number: 84 of 162 with model AverageValueNaive for Validation 1\n",
            "84 - AverageValueNaive with avg smape 17.0: \n",
            "Model Number: 85 of 162 with model UnobservedComponents for Validation 1\n",
            "85 - UnobservedComponents with avg smape 7.3: \n",
            "Model Number: 86 of 162 with model UnobservedComponents for Validation 1\n",
            "86 - UnobservedComponents with avg smape 7.3: \n",
            "Model Number: 87 of 162 with model ETS for Validation 1\n",
            "87 - ETS with avg smape 12.57: \n",
            "Model Number: 88 of 162 with model UnobservedComponents for Validation 1\n",
            "88 - UnobservedComponents with avg smape 7.67: \n",
            "Model Number: 89 of 162 with model UnobservedComponents for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89 - UnobservedComponents with avg smape 7.67: \n",
            "Model Number: 90 of 162 with model UnobservedComponents for Validation 1\n",
            "90 - UnobservedComponents with avg smape 7.34: \n",
            "Model Number: 91 of 162 with model UnobservedComponents for Validation 1\n",
            "91 - UnobservedComponents with avg smape 7.34: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 92 of 162 with model Theta for Validation 1\n",
            "92 - Theta with avg smape 11.67: \n",
            "Model Number: 93 of 162 with model Theta for Validation 1\n",
            "93 - Theta with avg smape 11.61: \n",
            "Model Number: 94 of 162 with model UnobservedComponents for Validation 1\n",
            "94 - UnobservedComponents with avg smape 7.42: \n",
            "Model Number: 95 of 162 with model LastValueNaive for Validation 1\n",
            "95 - LastValueNaive with avg smape 11.82: \n",
            "Model Number: 96 of 162 with model LastValueNaive for Validation 1\n",
            "96 - LastValueNaive with avg smape 11.82: \n",
            "Model Number: 97 of 162 with model LastValueNaive for Validation 1\n",
            "97 - LastValueNaive with avg smape 11.98: \n",
            "Model Number: 98 of 162 with model Theta for Validation 1\n",
            "98 - Theta with avg smape 13.53: \n",
            "Model Number: 99 of 162 with model AverageValueNaive for Validation 1\n",
            "99 - AverageValueNaive with avg smape 14.01: \n",
            "Model Number: 100 of 162 with model LastValueNaive for Validation 1\n",
            "100 - LastValueNaive with avg smape 11.59: \n",
            "Model Number: 101 of 162 with model Theta for Validation 1\n",
            "101 - Theta with avg smape 13.48: \n",
            "Model Number: 102 of 162 with model LastValueNaive for Validation 1\n",
            "102 - LastValueNaive with avg smape 13.6: \n",
            "Model Number: 103 of 162 with model Theta for Validation 1\n",
            "103 - Theta with avg smape 15.09: \n",
            "Model Number: 104 of 162 with model Theta for Validation 1\n",
            "104 - Theta with avg smape 13.46: \n",
            "Model Number: 105 of 162 with model Theta for Validation 1\n",
            "105 - Theta with avg smape 13.46: \n",
            "Model Number: 106 of 162 with model Theta for Validation 1\n",
            "106 - Theta with avg smape 13.46: \n",
            "Model Number: 107 of 162 with model Theta for Validation 1\n",
            "107 - Theta with avg smape 13.57: \n",
            "Model Number: 108 of 162 with model LastValueNaive for Validation 1\n",
            "108 - LastValueNaive with avg smape 14.63: \n",
            "Model Number: 109 of 162 with model LastValueNaive for Validation 1\n",
            "109 - LastValueNaive with avg smape 14.63: \n",
            "Model Number: 110 of 162 with model AverageValueNaive for Validation 1\n",
            "110 - AverageValueNaive with avg smape 11.04: \n",
            "Model Number: 111 of 162 with model AverageValueNaive for Validation 1\n",
            "111 - AverageValueNaive with avg smape 10.19: \n",
            "Model Number: 112 of 162 with model AverageValueNaive for Validation 1\n",
            "112 - AverageValueNaive with avg smape 10.19: \n",
            "Model Number: 113 of 162 with model AverageValueNaive for Validation 1\n",
            "113 - AverageValueNaive with avg smape 10.19: \n",
            "Model Number: 114 of 162 with model GLS for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114 - GLS with avg smape 14.18: \n",
            "Model Number: 115 of 162 with model FBProphet for Validation 1\n",
            "115 - FBProphet with avg smape 10.72: \n",
            "Model Number: 116 of 162 with model GLS for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116 - GLS with avg smape 14.41: \n",
            "Model Number: 117 of 162 with model FBProphet for Validation 1\n",
            "117 - FBProphet with avg smape 10.05: \n",
            "Model Number: 118 of 162 with model GLS for Validation 1\n",
            "118 - GLS with avg smape 4.8: \n",
            "Model Number: 119 of 162 with model SectionalMotif for Validation 1\n",
            "119 - SectionalMotif with avg smape 12.91: \n",
            "Model Number: 120 of 162 with model GLS for Validation 1\n",
            "120 - GLS with avg smape 11.44: \n",
            "Model Number: 121 of 162 with model GLS for Validation 1\n",
            "121 - GLS with avg smape 11.44: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 122 of 162 with model FBProphet for Validation 1\n",
            "122 - FBProphet with avg smape 11.44: \n",
            "Model Number: 123 of 162 with model GLS for Validation 1\n",
            "123 - GLS with avg smape 11.44: \n",
            "Model Number: 124 of 162 with model SectionalMotif for Validation 1\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (99)') in model 124: SectionalMotif\n",
            "Model Number: 125 of 162 with model GLS for Validation 1\n",
            "125 - GLS with avg smape 11.44: \n",
            "Model Number: 126 of 162 with model GLS for Validation 1\n",
            "126 - GLS with avg smape 11.36: \n",
            "Model Number: 127 of 162 with model SectionalMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127 - SectionalMotif with avg smape 14.05: \n",
            "Model Number: 128 of 162 with model SectionalMotif for Validation 1\n",
            "128 - SectionalMotif with avg smape 17.58: \n",
            "Model Number: 129 of 162 with model SectionalMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129 - SectionalMotif with avg smape 11.48: \n",
            "Model Number: 130 of 162 with model FBProphet for Validation 1\n",
            "130 - FBProphet with avg smape 11.77: \n",
            "Model Number: 131 of 162 with model SectionalMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 - SectionalMotif with avg smape 16.67: \n",
            "Model Number: 132 of 162 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132 - FBProphet with avg smape 11.42: \n",
            "Model Number: 133 of 162 with model FBProphet for Validation 1\n",
            "133 - FBProphet with avg smape 11.72: \n",
            "Model Number: 134 of 162 with model UnivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134 - UnivariateRegression with avg smape 9.25: \n",
            "Model Number: 135 of 162 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 - FBProphet with avg smape 11.96: \n",
            "Model Number: 136 of 162 with model FBProphet for Validation 1\n",
            "136 - FBProphet with avg smape 15.67: \n",
            "Model Number: 137 of 162 with model NVAR for Validation 1\n",
            "137 - NVAR with avg smape 16.37: \n",
            "Model Number: 138 of 162 with model NVAR for Validation 1\n",
            "138 - NVAR with avg smape 16.36: \n",
            "Model Number: 139 of 162 with model NVAR for Validation 1\n",
            "139 - NVAR with avg smape 11.19: \n",
            "Model Number: 140 of 162 with model NVAR for Validation 1\n",
            "140 - NVAR with avg smape 11.19: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 141 of 162 with model FBProphet for Validation 1\n",
            "141 - FBProphet with avg smape 15.09: \n",
            "Model Number: 142 of 162 with model NVAR for Validation 1\n",
            "142 - NVAR with avg smape 11.2: \n",
            "Model Number: 143 of 162 with model NVAR for Validation 1\n",
            "143 - NVAR with avg smape 11.57: \n",
            "Model Number: 144 of 162 with model NVAR for Validation 1\n",
            "144 - NVAR with avg smape 11.06: \n",
            "Model Number: 145 of 162 with model ConstantNaive for Validation 1\n",
            "145 - ConstantNaive with avg smape 12.67: \n",
            "Model Number: 146 of 162 with model ConstantNaive for Validation 1\n",
            "146 - ConstantNaive with avg smape 11.44: \n",
            "Model Number: 147 of 162 with model ConstantNaive for Validation 1\n",
            "147 - ConstantNaive with avg smape 11.44: \n",
            "Model Number: 148 of 162 with model ConstantNaive for Validation 1\n",
            "148 - ConstantNaive with avg smape 11.44: \n",
            "Model Number: 149 of 162 with model ConstantNaive for Validation 1\n",
            "149 - ConstantNaive with avg smape 11.44: \n",
            "Model Number: 150 of 162 with model NVAR for Validation 1\n",
            "150 - NVAR with avg smape 13.51: \n",
            "Model Number: 151 of 162 with model NVAR for Validation 1\n",
            "151 - NVAR with avg smape 13.51: \n",
            "Model Number: 152 of 162 with model ConstantNaive for Validation 1\n",
            "152 - ConstantNaive with avg smape 11.44: \n",
            "Model Number: 153 of 162 with model ConstantNaive for Validation 1\n",
            "153 - ConstantNaive with avg smape 11.44: \n",
            "Model Number: 154 of 162 with model ConstantNaive for Validation 1\n",
            "154 - ConstantNaive with avg smape 15.55: \n",
            "Model Number: 155 of 162 with model ConstantNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155 - ConstantNaive with avg smape 15.55: \n",
            "Model Number: 156 of 162 with model UnivariateRegression for Validation 1\n",
            "156 - UnivariateRegression with avg smape 18.81: \n",
            "Model Number: 157 of 162 with model SectionalMotif for Validation 1\n",
            "157 - SectionalMotif with avg smape 10.35: \n",
            "Model Number: 158 of 162 with model UnivariateRegression for Validation 1\n",
            "158 - UnivariateRegression with avg smape 13.33: \n",
            "Model Number: 159 of 162 with model UnivariateRegression for Validation 1\n",
            "159 - UnivariateRegression with avg smape 21.53: \n",
            "Model Number: 160 of 162 with model UnivariateRegression for Validation 1\n",
            "160 - UnivariateRegression with avg smape 23.33: \n",
            "Model Number: 161 of 162 with model UnivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161 - UnivariateRegression with avg smape 24.36: \n",
            "Model Number: 162 of 162 with model GLM for Validation 1\n",
            "162 - GLM with avg smape 59.22: \n",
            "Validation Round: 2\n",
            "Model Number: 1 of 162 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 1413.7423631177226, tolerance: 442.87459740259743\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ˆ 1 - Ensemble with avg smape 5.47: \n",
            "Model Number: 2 of 162 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 1413.7423631177226, tolerance: 442.87459740259743\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 - Ensemble with avg smape 7.16: \n",
            "Model Number: 3 of 162 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 1413.7423631177226, tolerance: 442.87459740259743\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 - Ensemble with avg smape 7.26: \n",
            "Model Number: 4 of 162 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 1413.7423631177226, tolerance: 442.87459740259743\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 - Ensemble with avg smape 5.49: \n",
            "Model Number: 5 of 162 with model WindowRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 1413.7423631177226, tolerance: 442.87459740259743\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 - WindowRegression with avg smape 9.21: \n",
            "Model Number: 6 of 162 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 1413.7423631177226, tolerance: 442.87459740259743\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 - Ensemble with avg smape 6.56: \n",
            "Model Number: 7 of 162 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 1413.7423631177226, tolerance: 442.87459740259743\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 - Ensemble with avg smape 5.51: \n",
            "Model Number: 8 of 162 with model WindowRegression for Validation 2\n",
            "ðŸ“ˆ 8 - WindowRegression with avg smape 2.75: \n",
            "Model Number: 9 of 162 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 - Ensemble with avg smape 6.3: \n",
            "Model Number: 10 of 162 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 - Ensemble with avg smape 6.38: \n",
            "Model Number: 11 of 162 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    1.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 - DatepartRegression with avg smape 5.51: \n",
            "Model Number: 12 of 162 with model MultivariateMotif for Validation 2\n",
            "12 - MultivariateMotif with avg smape 9.26: \n",
            "Model Number: 13 of 162 with model WindowRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 6s 8ms/step - loss: 149.6970\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 206.3599\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 145.7396\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 162.6722\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 146.0804\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 109.8545\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 102.8244\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 120.7052\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 114.1555\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 109.5000\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 121.2398\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 110.7785\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 103.1867\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 107.3157\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 103.1258\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 100.1274\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 103.8229\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 100.0064\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 105.5797\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 128.4379\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 111.6757\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 130.4763\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 111.2999\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 165.1409\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 109.1040\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 124.8856\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 106.6413\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 127.5144\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 100.4004\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 140.9630\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 122.7203\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 143.1145\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 151.3564\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 103.5759\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 127.1371\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 109.8508\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 106.1554\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 103.5799\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 119.9762\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 107.9838\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 132.4165\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 113.0815\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 118.6979\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 124.4383\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 100.1646\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 116.8109\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 107.3738\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 112.7641\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 109.4687\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 108.8547\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 106.2393\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 116.0639\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 101.0865\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 100.7898\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 100.4938\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 104.5633\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 100.9344\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 100.5364\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 136.8767\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 164.2682\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 133.2217\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 124.3031\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 132.6985\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 107.5516\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 109.7929\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 102.2343\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 104.6130\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 105.0173\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 110.9108\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 99.3717\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 108.0586\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 107.0305\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 109.0178\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 106.0296\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.8286\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 102.7597\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 104.7308\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 106.2760\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 115.6500\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 104.1401\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 141.8894\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 118.6809\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 102.0892\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 112.0377\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.8972\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 113.8434\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 106.3060\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 130.4458\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 108.1543\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 151.9504\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 178.6130\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 156.1801\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 100.0533\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 173.5436\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 206.4588\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 176.6579\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 136.0303\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 130.4988\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 136.9620\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 104.5818\n",
            "13 - WindowRegression with avg smape 5.79: \n",
            "Model Number: 14 of 162 with model DatepartRegression for Validation 2\n",
            "14 - DatepartRegression with avg smape 4.95: \n",
            "Model Number: 15 of 162 with model WindowRegression for Validation 2\n",
            "15 - WindowRegression with avg smape 9.68: \n",
            "Model Number: 16 of 162 with model UnivariateMotif for Validation 2\n",
            "16 - UnivariateMotif with avg smape 5.61: \n",
            "Model Number: 17 of 162 with model UnivariateMotif for Validation 2\n",
            "17 - UnivariateMotif with avg smape 5.61: \n",
            "Model Number: 18 of 162 with model UnivariateMotif for Validation 2\n",
            "18 - UnivariateMotif with avg smape 5.95: \n",
            "Model Number: 19 of 162 with model UnivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 - UnivariateMotif with avg smape 5.31: \n",
            "Model Number: 20 of 162 with model UnivariateMotif for Validation 2\n",
            "20 - UnivariateMotif with avg smape 5.07: \n",
            "Model Number: 21 of 162 with model WindowRegression for Validation 2\n",
            "21 - WindowRegression with avg smape 6.28: \n",
            "Model Number: 22 of 162 with model UnivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 - UnivariateMotif with avg smape 5.92: \n",
            "Model Number: 23 of 162 with model DatepartRegression for Validation 2\n",
            "23 - DatepartRegression with avg smape 4.73: \n",
            "Model Number: 24 of 162 with model MultivariateMotif for Validation 2\n",
            "24 - MultivariateMotif with avg smape 10.45: \n",
            "Model Number: 25 of 162 with model UnivariateMotif for Validation 2\n",
            "25 - UnivariateMotif with avg smape 5.66: \n",
            "Model Number: 26 of 162 with model WindowRegression for Validation 2\n",
            "26 - WindowRegression with avg smape 4.44: \n",
            "Model Number: 27 of 162 with model WindowRegression for Validation 2\n",
            "27 - WindowRegression with avg smape 4.44: \n",
            "Model Number: 28 of 162 with model WindowRegression for Validation 2\n",
            "28 - WindowRegression with avg smape 9.73: \n",
            "Model Number: 29 of 162 with model MultivariateMotif for Validation 2\n",
            "29 - MultivariateMotif with avg smape 5.17: \n",
            "Model Number: 30 of 162 with model WindowRegression for Validation 2\n",
            "30 - WindowRegression with avg smape 4.28: \n",
            "Model Number: 31 of 162 with model MultivariateMotif for Validation 2\n",
            "31 - MultivariateMotif with avg smape 5.98: \n",
            "Model Number: 32 of 162 with model MultivariateMotif for Validation 2\n",
            "32 - MultivariateMotif with avg smape 6.3: \n",
            "Model Number: 33 of 162 with model MultivariateMotif for Validation 2\n",
            "33 - MultivariateMotif with avg smape 4.26: \n",
            "Model Number: 34 of 162 with model DatepartRegression for Validation 2\n",
            "34 - DatepartRegression with avg smape 4.94: \n",
            "Model Number: 35 of 162 with model MultivariateMotif for Validation 2\n",
            "35 - MultivariateMotif with avg smape 11.0: \n",
            "Model Number: 36 of 162 with model UnivariateMotif for Validation 2\n",
            "36 - UnivariateMotif with avg smape 6.32: \n",
            "Model Number: 37 of 162 with model UnivariateMotif for Validation 2\n",
            "37 - UnivariateMotif with avg smape 6.32: \n",
            "Model Number: 38 of 162 with model SeasonalNaive for Validation 2\n",
            "38 - SeasonalNaive with avg smape 4.61: \n",
            "Model Number: 39 of 162 with model MultivariateMotif for Validation 2\n",
            "39 - MultivariateMotif with avg smape 5.98: \n",
            "Model Number: 40 of 162 with model MultivariateMotif for Validation 2\n",
            "40 - MultivariateMotif with avg smape 11.71: \n",
            "Model Number: 41 of 162 with model MultivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41 - MultivariateRegression with avg smape 6.42: \n",
            "Model Number: 42 of 162 with model SeasonalNaive for Validation 2\n",
            "42 - SeasonalNaive with avg smape 4.49: \n",
            "Model Number: 43 of 162 with model SeasonalNaive for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43 - SeasonalNaive with avg smape 4.49: \n",
            "Model Number: 44 of 162 with model SeasonalNaive for Validation 2\n",
            "44 - SeasonalNaive with avg smape 4.43: \n",
            "Model Number: 45 of 162 with model MultivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 - MultivariateRegression with avg smape 5.72: \n",
            "Model Number: 46 of 162 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 - DatepartRegression with avg smape 10.4: \n",
            "Model Number: 47 of 162 with model UnivariateRegression for Validation 2\n",
            "47 - UnivariateRegression with avg smape 8.65: \n",
            "Model Number: 48 of 162 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 - DatepartRegression with avg smape 10.55: \n",
            "Model Number: 49 of 162 with model MultivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 - MultivariateRegression with avg smape 6.88: \n",
            "Model Number: 50 of 162 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 - DatepartRegression with avg smape 10.56: \n",
            "Model Number: 51 of 162 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51 - DatepartRegression with avg smape 10.62: \n",
            "Model Number: 52 of 162 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52 - DatepartRegression with avg smape 10.6: \n",
            "Model Number: 53 of 162 with model MultivariateRegression for Validation 2\n",
            "53 - MultivariateRegression with avg smape 7.71: \n",
            "Model Number: 54 of 162 with model AverageValueNaive for Validation 2\n",
            "54 - AverageValueNaive with avg smape 3.57: \n",
            "Model Number: 55 of 162 with model SectionalMotif for Validation 2\n",
            "55 - SectionalMotif with avg smape 10.49: \n",
            "Model Number: 56 of 162 with model MultivariateRegression for Validation 2\n",
            "56 - MultivariateRegression with avg smape 6.48: \n",
            "Model Number: 57 of 162 with model MultivariateRegression for Validation 2\n",
            "57 - MultivariateRegression with avg smape 9.56: \n",
            "Model Number: 58 of 162 with model GLS for Validation 2\n",
            "ðŸ“ˆ 58 - GLS with avg smape 2.07: \n",
            "Model Number: 59 of 162 with model MultivariateRegression for Validation 2\n",
            "59 - MultivariateRegression with avg smape 6.05: \n",
            "Model Number: 60 of 162 with model AverageValueNaive for Validation 2\n",
            "60 - AverageValueNaive with avg smape 3.65: \n",
            "Model Number: 61 of 162 with model SectionalMotif for Validation 2\n",
            "61 - SectionalMotif with avg smape 8.47: \n",
            "Model Number: 62 of 162 with model SeasonalNaive for Validation 2\n",
            "62 - SeasonalNaive with avg smape 4.58: \n",
            "Model Number: 63 of 162 with model MultivariateRegression for Validation 2\n",
            "63 - MultivariateRegression with avg smape 7.68: \n",
            "Model Number: 64 of 162 with model MultivariateRegression for Validation 2\n",
            "64 - MultivariateRegression with avg smape 8.25: \n",
            "Model Number: 65 of 162 with model AverageValueNaive for Validation 2\n",
            "65 - AverageValueNaive with avg smape 3.72: \n",
            "Model Number: 66 of 162 with model ETS for Validation 2\n",
            "66 - ETS with avg smape 7.68: \n",
            "Model Number: 67 of 162 with model ETS for Validation 2\n",
            "67 - ETS with avg smape 7.37: \n",
            "Model Number: 68 of 162 with model ETS for Validation 2\n",
            "68 - ETS with avg smape 7.37: \n",
            "Model Number: 69 of 162 with model UnivariateRegression for Validation 2\n",
            "69 - UnivariateRegression with avg smape 4.9: \n",
            "Model Number: 70 of 162 with model UnobservedComponents for Validation 2\n",
            "70 - UnobservedComponents with avg smape 8.56: \n",
            "Model Number: 71 of 162 with model UnobservedComponents for Validation 2\n",
            "71 - UnobservedComponents with avg smape 8.48: \n",
            "Model Number: 72 of 162 with model SeasonalNaive for Validation 2\n",
            "72 - SeasonalNaive with avg smape 6.88: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 73 of 162 with model SeasonalNaive for Validation 2\n",
            "73 - SeasonalNaive with avg smape 6.55: \n",
            "Model Number: 74 of 162 with model SeasonalNaive for Validation 2\n",
            "74 - SeasonalNaive with avg smape 6.55: \n",
            "Model Number: 75 of 162 with model SeasonalNaive for Validation 2\n",
            "75 - SeasonalNaive with avg smape 6.5: \n",
            "Model Number: 76 of 162 with model ETS for Validation 2\n",
            "76 - ETS with avg smape 7.12: \n",
            "Model Number: 77 of 162 with model LastValueNaive for Validation 2\n",
            "77 - LastValueNaive with avg smape 8.98: \n",
            "Model Number: 78 of 162 with model UnivariateRegression for Validation 2\n",
            "78 - UnivariateRegression with avg smape 4.95: \n",
            "Model Number: 79 of 162 with model ETS for Validation 2\n",
            "79 - ETS with avg smape 7.33: \n",
            "Model Number: 80 of 162 with model ETS for Validation 2\n",
            "80 - ETS with avg smape 7.33: \n",
            "Model Number: 81 of 162 with model LastValueNaive for Validation 2\n",
            "81 - LastValueNaive with avg smape 8.75: \n",
            "Model Number: 82 of 162 with model ETS for Validation 2\n",
            "82 - ETS with avg smape 7.16: \n",
            "Model Number: 83 of 162 with model ETS for Validation 2\n",
            "83 - ETS with avg smape 7.15: \n",
            "Model Number: 84 of 162 with model AverageValueNaive for Validation 2\n",
            "84 - AverageValueNaive with avg smape 6.19: \n",
            "Model Number: 85 of 162 with model UnobservedComponents for Validation 2\n",
            "85 - UnobservedComponents with avg smape 8.69: \n",
            "Model Number: 86 of 162 with model UnobservedComponents for Validation 2\n",
            "86 - UnobservedComponents with avg smape 8.69: \n",
            "Model Number: 87 of 162 with model ETS for Validation 2\n",
            "87 - ETS with avg smape 6.65: \n",
            "Model Number: 88 of 162 with model UnobservedComponents for Validation 2\n",
            "88 - UnobservedComponents with avg smape 8.53: \n",
            "Model Number: 89 of 162 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89 - UnobservedComponents with avg smape 8.53: \n",
            "Model Number: 90 of 162 with model UnobservedComponents for Validation 2\n",
            "90 - UnobservedComponents with avg smape 8.59: \n",
            "Model Number: 91 of 162 with model UnobservedComponents for Validation 2\n",
            "91 - UnobservedComponents with avg smape 8.59: \n",
            "Model Number: 92 of 162 with model Theta for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92 - Theta with avg smape 10.49: \n",
            "Model Number: 93 of 162 with model Theta for Validation 2\n",
            "93 - Theta with avg smape 10.48: \n",
            "Model Number: 94 of 162 with model UnobservedComponents for Validation 2\n",
            "94 - UnobservedComponents with avg smape 8.54: \n",
            "Model Number: 95 of 162 with model LastValueNaive for Validation 2\n",
            "95 - LastValueNaive with avg smape 9.23: \n",
            "Model Number: 96 of 162 with model LastValueNaive for Validation 2\n",
            "96 - LastValueNaive with avg smape 9.23: \n",
            "Model Number: 97 of 162 with model LastValueNaive for Validation 2\n",
            "97 - LastValueNaive with avg smape 9.19: \n",
            "Model Number: 98 of 162 with model Theta for Validation 2\n",
            "98 - Theta with avg smape 9.65: \n",
            "Model Number: 99 of 162 with model AverageValueNaive for Validation 2\n",
            "99 - AverageValueNaive with avg smape 9.29: \n",
            "Model Number: 100 of 162 with model LastValueNaive for Validation 2\n",
            "100 - LastValueNaive with avg smape 9.38: \n",
            "Model Number: 101 of 162 with model Theta for Validation 2\n",
            "101 - Theta with avg smape 12.9: \n",
            "Model Number: 102 of 162 with model LastValueNaive for Validation 2\n",
            "102 - LastValueNaive with avg smape 9.81: \n",
            "Model Number: 103 of 162 with model Theta for Validation 2\n",
            "103 - Theta with avg smape 9.8: \n",
            "Model Number: 104 of 162 with model Theta for Validation 2\n",
            "104 - Theta with avg smape 9.72: \n",
            "Model Number: 105 of 162 with model Theta for Validation 2\n",
            "105 - Theta with avg smape 9.72: \n",
            "Model Number: 106 of 162 with model Theta for Validation 2\n",
            "106 - Theta with avg smape 9.72: \n",
            "Model Number: 107 of 162 with model Theta for Validation 2\n",
            "107 - Theta with avg smape 9.74: \n",
            "Model Number: 108 of 162 with model LastValueNaive for Validation 2\n",
            "108 - LastValueNaive with avg smape 7.97: \n",
            "Model Number: 109 of 162 with model LastValueNaive for Validation 2\n",
            "109 - LastValueNaive with avg smape 7.97: \n",
            "Model Number: 110 of 162 with model AverageValueNaive for Validation 2\n",
            "110 - AverageValueNaive with avg smape 2.91: \n",
            "Model Number: 111 of 162 with model AverageValueNaive for Validation 2\n",
            "111 - AverageValueNaive with avg smape 8.88: \n",
            "Model Number: 112 of 162 with model AverageValueNaive for Validation 2\n",
            "112 - AverageValueNaive with avg smape 8.88: \n",
            "Model Number: 113 of 162 with model AverageValueNaive for Validation 2\n",
            "113 - AverageValueNaive with avg smape 8.88: \n",
            "Model Number: 114 of 162 with model GLS for Validation 2\n",
            "114 - GLS with avg smape 10.2: \n",
            "Model Number: 115 of 162 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115 - FBProphet with avg smape 14.18: \n",
            "Model Number: 116 of 162 with model GLS for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116 - GLS with avg smape 10.06: \n",
            "Model Number: 117 of 162 with model FBProphet for Validation 2\n",
            "117 - FBProphet with avg smape 12.09: \n",
            "Model Number: 118 of 162 with model GLS for Validation 2\n",
            "118 - GLS with avg smape 14.11: \n",
            "Model Number: 119 of 162 with model SectionalMotif for Validation 2\n",
            "119 - SectionalMotif with avg smape 11.76: \n",
            "Model Number: 120 of 162 with model GLS for Validation 2\n",
            "120 - GLS with avg smape 12.78: \n",
            "Model Number: 121 of 162 with model GLS for Validation 2\n",
            "121 - GLS with avg smape 12.78: \n",
            "Model Number: 122 of 162 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122 - FBProphet with avg smape 12.78: \n",
            "Model Number: 123 of 162 with model GLS for Validation 2\n",
            "123 - GLS with avg smape 12.67: \n",
            "Model Number: 124 of 162 with model SectionalMotif for Validation 2\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (87)') in model 124: SectionalMotif\n",
            "Model Number: 125 of 162 with model GLS for Validation 2\n",
            "125 - GLS with avg smape 12.63: \n",
            "Model Number: 126 of 162 with model GLS for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126 - GLS with avg smape 15.9: \n",
            "Model Number: 127 of 162 with model SectionalMotif for Validation 2\n",
            "127 - SectionalMotif with avg smape 12.1: \n",
            "Model Number: 128 of 162 with model SectionalMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128 - SectionalMotif with avg smape 11.59: \n",
            "Model Number: 129 of 162 with model SectionalMotif for Validation 2\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (92)') in model 129: SectionalMotif\n",
            "Model Number: 130 of 162 with model FBProphet for Validation 2\n",
            "130 - FBProphet with avg smape 14.12: \n",
            "Model Number: 131 of 162 with model SectionalMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 - SectionalMotif with avg smape 13.38: \n",
            "Model Number: 132 of 162 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132 - FBProphet with avg smape 12.74: \n",
            "Model Number: 133 of 162 with model FBProphet for Validation 2\n",
            "133 - FBProphet with avg smape 14.02: \n",
            "Model Number: 134 of 162 with model UnivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134 - UnivariateRegression with avg smape 8.94: \n",
            "Model Number: 135 of 162 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 - FBProphet with avg smape 13.13: \n",
            "Model Number: 136 of 162 with model FBProphet for Validation 2\n",
            "136 - FBProphet with avg smape 11.52: \n",
            "Model Number: 137 of 162 with model NVAR for Validation 2\n",
            "137 - NVAR with avg smape 12.04: \n",
            "Model Number: 138 of 162 with model NVAR for Validation 2\n",
            "138 - NVAR with avg smape 12.05: \n",
            "Model Number: 139 of 162 with model NVAR for Validation 2\n",
            "139 - NVAR with avg smape 11.59: \n",
            "Model Number: 140 of 162 with model NVAR for Validation 2\n",
            "140 - NVAR with avg smape 11.59: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 141 of 162 with model FBProphet for Validation 2\n",
            "141 - FBProphet with avg smape 11.53: \n",
            "Model Number: 142 of 162 with model NVAR for Validation 2\n",
            "142 - NVAR with avg smape 11.55: \n",
            "Model Number: 143 of 162 with model NVAR for Validation 2\n",
            "143 - NVAR with avg smape 13.97: \n",
            "Model Number: 144 of 162 with model NVAR for Validation 2\n",
            "144 - NVAR with avg smape 11.5: \n",
            "Model Number: 145 of 162 with model ConstantNaive for Validation 2\n",
            "145 - ConstantNaive with avg smape 12.34: \n",
            "Model Number: 146 of 162 with model ConstantNaive for Validation 2\n",
            "146 - ConstantNaive with avg smape 12.79: \n",
            "Model Number: 147 of 162 with model ConstantNaive for Validation 2\n",
            "147 - ConstantNaive with avg smape 12.79: \n",
            "Model Number: 148 of 162 with model ConstantNaive for Validation 2\n",
            "148 - ConstantNaive with avg smape 12.78: \n",
            "Model Number: 149 of 162 with model ConstantNaive for Validation 2\n",
            "149 - ConstantNaive with avg smape 12.79: \n",
            "Model Number: 150 of 162 with model NVAR for Validation 2\n",
            "150 - NVAR with avg smape 15.18: \n",
            "Model Number: 151 of 162 with model NVAR for Validation 2\n",
            "151 - NVAR with avg smape 15.18: \n",
            "Model Number: 152 of 162 with model ConstantNaive for Validation 2\n",
            "152 - ConstantNaive with avg smape 12.37: \n",
            "Model Number: 153 of 162 with model ConstantNaive for Validation 2\n",
            "153 - ConstantNaive with avg smape 12.26: \n",
            "Model Number: 154 of 162 with model ConstantNaive for Validation 2\n",
            "154 - ConstantNaive with avg smape 6.86: \n",
            "Model Number: 155 of 162 with model ConstantNaive for Validation 2\n",
            "155 - ConstantNaive with avg smape 6.86: \n",
            "Model Number: 156 of 162 with model UnivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156 - UnivariateRegression with avg smape 12.9: \n",
            "Model Number: 157 of 162 with model SectionalMotif for Validation 2\n",
            "157 - SectionalMotif with avg smape 10.94: \n",
            "Model Number: 158 of 162 with model UnivariateRegression for Validation 2\n",
            "158 - UnivariateRegression with avg smape 24.21: \n",
            "Model Number: 159 of 162 with model UnivariateRegression for Validation 2\n",
            "159 - UnivariateRegression with avg smape 20.4: \n",
            "Model Number: 160 of 162 with model UnivariateRegression for Validation 2\n",
            "160 - UnivariateRegression with avg smape 19.66: \n",
            "Model Number: 161 of 162 with model UnivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161 - UnivariateRegression with avg smape 19.66: \n",
            "Model Number: 162 of 162 with model GLM for Validation 2\n",
            "162 - GLM with avg smape 58.33: \n",
            "Validation Round: 3\n",
            "Model Number: 1 of 162 with model Ensemble for Validation 3\n",
            "ðŸ“ˆ 1 - Ensemble with avg smape 2.43: \n",
            "Model Number: 2 of 162 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 - Ensemble with avg smape 3.09: \n",
            "Model Number: 3 of 162 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 - Ensemble with avg smape 3.53: \n",
            "Model Number: 4 of 162 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 - Ensemble with avg smape 5.2: \n",
            "Model Number: 5 of 162 with model WindowRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ˆ 5 - WindowRegression with avg smape 1.54: \n",
            "Model Number: 6 of 162 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 - Ensemble with avg smape 4.11: \n",
            "Model Number: 7 of 162 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 - Ensemble with avg smape 4.28: \n",
            "Model Number: 8 of 162 with model WindowRegression for Validation 3\n",
            "8 - WindowRegression with avg smape 10.72: \n",
            "Model Number: 9 of 162 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 - Ensemble with avg smape 5.32: \n",
            "Model Number: 10 of 162 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 - Ensemble with avg smape 5.33: \n",
            "Model Number: 11 of 162 with model DatepartRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 - DatepartRegression with avg smape 4.68: \n",
            "Model Number: 12 of 162 with model MultivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 - MultivariateMotif with avg smape 5.4: \n",
            "Model Number: 13 of 162 with model WindowRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 6s 11ms/step - loss: 131.3308\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 111.5591\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 126.8684\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 115.9832\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 108.9848\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 106.9187\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 107.9877\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 110.9230\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 104.7489\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 105.2363\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 99.4413\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 103.3374\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 100.0330\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 101.9816\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 99.2809\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 100.8702\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 99.1301\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 98.8217\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 107.4075\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 103.1188\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 115.6854\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 105.3788\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 108.4665\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 105.6164\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 105.3169\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 104.2683\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 103.5860\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 104.3354\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 101.5698\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 101.7760\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 104.8165\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 98.4660\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 114.6987\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 107.7750\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 105.9948\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 103.8119\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 101.5645\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 101.3614\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 103.5834\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 104.6545\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 100.8355\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 100.6262\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 99.7045\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 99.6596\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 102.4884\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.7819\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 99.4340\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 101.4167\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 101.5325\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 100.9620\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 99.8292\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 102.3325\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 104.2240\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 103.1335\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 98.0837\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 101.2454\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 100.6729\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 99.1801\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 99.3467\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 98.7368\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 100.7189\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 99.5058\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 98.8252\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 101.1561\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 100.8860\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 97.8727\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 104.6065\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 98.5702\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 102.7626\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 105.7866\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 103.1990\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 100.8822\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 99.2519\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 102.5766\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 98.0901\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 98.7935\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 102.2772\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 99.3450\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 101.1925\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 99.8551\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 98.6376\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 99.5117\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 99.1845\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 101.1024\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 101.5690\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 101.9069\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 99.1071\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 98.1548\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.3963\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 98.9715\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 98.5982\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 105.8897\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 102.7511\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 107.9994\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 101.8615\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 102.7043\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 99.9251\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 123.7138\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 110.6072\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 109.0549\n",
            "13 - WindowRegression with avg smape 7.16: \n",
            "Model Number: 14 of 162 with model DatepartRegression for Validation 3\n",
            "14 - DatepartRegression with avg smape 4.35: \n",
            "Model Number: 15 of 162 with model WindowRegression for Validation 3\n",
            "15 - WindowRegression with avg smape 3.33: \n",
            "Model Number: 16 of 162 with model UnivariateMotif for Validation 3\n",
            "16 - UnivariateMotif with avg smape 6.44: \n",
            "Model Number: 17 of 162 with model UnivariateMotif for Validation 3\n",
            "17 - UnivariateMotif with avg smape 6.44: \n",
            "Model Number: 18 of 162 with model UnivariateMotif for Validation 3\n",
            "18 - UnivariateMotif with avg smape 7.26: \n",
            "Model Number: 19 of 162 with model UnivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 - UnivariateMotif with avg smape 6.43: \n",
            "Model Number: 20 of 162 with model UnivariateMotif for Validation 3\n",
            "20 - UnivariateMotif with avg smape 7.03: \n",
            "Model Number: 21 of 162 with model WindowRegression for Validation 3\n",
            "21 - WindowRegression with avg smape 6.35: \n",
            "Model Number: 22 of 162 with model UnivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 - UnivariateMotif with avg smape 6.8: \n",
            "Model Number: 23 of 162 with model DatepartRegression for Validation 3\n",
            "23 - DatepartRegression with avg smape 4.78: \n",
            "Model Number: 24 of 162 with model MultivariateMotif for Validation 3\n",
            "24 - MultivariateMotif with avg smape 5.71: \n",
            "Model Number: 25 of 162 with model UnivariateMotif for Validation 3\n",
            "25 - UnivariateMotif with avg smape 4.67: \n",
            "Model Number: 26 of 162 with model WindowRegression for Validation 3\n",
            "26 - WindowRegression with avg smape 3.72: \n",
            "Model Number: 27 of 162 with model WindowRegression for Validation 3\n",
            "27 - WindowRegression with avg smape 3.72: \n",
            "Model Number: 28 of 162 with model WindowRegression for Validation 3\n",
            "28 - WindowRegression with avg smape 2.59: \n",
            "Model Number: 29 of 162 with model MultivariateMotif for Validation 3\n",
            "29 - MultivariateMotif with avg smape 7.17: \n",
            "Model Number: 30 of 162 with model WindowRegression for Validation 3\n",
            "30 - WindowRegression with avg smape 3.87: \n",
            "Model Number: 31 of 162 with model MultivariateMotif for Validation 3\n",
            "31 - MultivariateMotif with avg smape 8.4: \n",
            "Model Number: 32 of 162 with model MultivariateMotif for Validation 3\n",
            "32 - MultivariateMotif with avg smape 8.4: \n",
            "Model Number: 33 of 162 with model MultivariateMotif for Validation 3\n",
            "33 - MultivariateMotif with avg smape 6.97: \n",
            "Model Number: 34 of 162 with model DatepartRegression for Validation 3\n",
            "34 - DatepartRegression with avg smape 3.9: \n",
            "Model Number: 35 of 162 with model MultivariateMotif for Validation 3\n",
            "35 - MultivariateMotif with avg smape 6.87: \n",
            "Model Number: 36 of 162 with model UnivariateMotif for Validation 3\n",
            "36 - UnivariateMotif with avg smape 9.03: \n",
            "Model Number: 37 of 162 with model UnivariateMotif for Validation 3\n",
            "37 - UnivariateMotif with avg smape 9.03: \n",
            "Model Number: 38 of 162 with model SeasonalNaive for Validation 3\n",
            "38 - SeasonalNaive with avg smape 6.95: \n",
            "Model Number: 39 of 162 with model MultivariateMotif for Validation 3\n",
            "39 - MultivariateMotif with avg smape 9.62: \n",
            "Model Number: 40 of 162 with model MultivariateMotif for Validation 3\n",
            "40 - MultivariateMotif with avg smape 6.97: \n",
            "Model Number: 41 of 162 with model MultivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41 - MultivariateRegression with avg smape 5.24: \n",
            "Model Number: 42 of 162 with model SeasonalNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42 - SeasonalNaive with avg smape 7.05: \n",
            "Model Number: 43 of 162 with model SeasonalNaive for Validation 3\n",
            "43 - SeasonalNaive with avg smape 7.05: \n",
            "Model Number: 44 of 162 with model SeasonalNaive for Validation 3\n",
            "44 - SeasonalNaive with avg smape 6.95: \n",
            "Model Number: 45 of 162 with model MultivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 - MultivariateRegression with avg smape 7.42: \n",
            "Model Number: 46 of 162 with model DatepartRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 - DatepartRegression with avg smape 4.65: \n",
            "Model Number: 47 of 162 with model UnivariateRegression for Validation 3\n",
            "47 - UnivariateRegression with avg smape 8.96: \n",
            "Model Number: 48 of 162 with model DatepartRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 - DatepartRegression with avg smape 4.68: \n",
            "Model Number: 49 of 162 with model MultivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 - MultivariateRegression with avg smape 7.78: \n",
            "Model Number: 50 of 162 with model DatepartRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 - DatepartRegression with avg smape 4.81: \n",
            "Model Number: 51 of 162 with model DatepartRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51 - DatepartRegression with avg smape 4.85: \n",
            "Model Number: 52 of 162 with model DatepartRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52 - DatepartRegression with avg smape 4.79: \n",
            "Model Number: 53 of 162 with model MultivariateRegression for Validation 3\n",
            "53 - MultivariateRegression with avg smape 7.59: \n",
            "Model Number: 54 of 162 with model AverageValueNaive for Validation 3\n",
            "54 - AverageValueNaive with avg smape 7.94: \n",
            "Model Number: 55 of 162 with model SectionalMotif for Validation 3\n",
            "55 - SectionalMotif with avg smape 1.63: \n",
            "Model Number: 56 of 162 with model MultivariateRegression for Validation 3\n",
            "56 - MultivariateRegression with avg smape 7.36: \n",
            "Model Number: 57 of 162 with model MultivariateRegression for Validation 3\n",
            "57 - MultivariateRegression with avg smape 11.26: \n",
            "Model Number: 58 of 162 with model GLS for Validation 3\n",
            "58 - GLS with avg smape 8.09: \n",
            "Model Number: 59 of 162 with model MultivariateRegression for Validation 3\n",
            "59 - MultivariateRegression with avg smape 7.61: \n",
            "Model Number: 60 of 162 with model AverageValueNaive for Validation 3\n",
            "60 - AverageValueNaive with avg smape 8.49: \n",
            "Model Number: 61 of 162 with model SectionalMotif for Validation 3\n",
            "61 - SectionalMotif with avg smape 7.68: \n",
            "Model Number: 62 of 162 with model SeasonalNaive for Validation 3\n",
            "62 - SeasonalNaive with avg smape 6.71: \n",
            "Model Number: 63 of 162 with model MultivariateRegression for Validation 3\n",
            "63 - MultivariateRegression with avg smape 6.95: \n",
            "Model Number: 64 of 162 with model MultivariateRegression for Validation 3\n",
            "64 - MultivariateRegression with avg smape 7.77: \n",
            "Model Number: 65 of 162 with model AverageValueNaive for Validation 3\n",
            "65 - AverageValueNaive with avg smape 6.94: \n",
            "Model Number: 66 of 162 with model ETS for Validation 3\n",
            "66 - ETS with avg smape 7.05: \n",
            "Model Number: 67 of 162 with model ETS for Validation 3\n",
            "67 - ETS with avg smape 7.2: \n",
            "Model Number: 68 of 162 with model ETS for Validation 3\n",
            "68 - ETS with avg smape 7.2: \n",
            "Model Number: 69 of 162 with model UnivariateRegression for Validation 3\n",
            "69 - UnivariateRegression with avg smape 3.18: \n",
            "Model Number: 70 of 162 with model UnobservedComponents for Validation 3\n",
            "70 - UnobservedComponents with avg smape 8.1: \n",
            "Model Number: 71 of 162 with model UnobservedComponents for Validation 3\n",
            "71 - UnobservedComponents with avg smape 8.15: \n",
            "Model Number: 72 of 162 with model SeasonalNaive for Validation 3\n",
            "72 - SeasonalNaive with avg smape 8.58: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 73 of 162 with model SeasonalNaive for Validation 3\n",
            "73 - SeasonalNaive with avg smape 7.63: \n",
            "Model Number: 74 of 162 with model SeasonalNaive for Validation 3\n",
            "74 - SeasonalNaive with avg smape 7.63: \n",
            "Model Number: 75 of 162 with model SeasonalNaive for Validation 3\n",
            "75 - SeasonalNaive with avg smape 7.72: \n",
            "Model Number: 76 of 162 with model ETS for Validation 3\n",
            "76 - ETS with avg smape 6.35: \n",
            "Model Number: 77 of 162 with model LastValueNaive for Validation 3\n",
            "77 - LastValueNaive with avg smape 7.78: \n",
            "Model Number: 78 of 162 with model UnivariateRegression for Validation 3\n",
            "78 - UnivariateRegression with avg smape 3.53: \n",
            "Model Number: 79 of 162 with model ETS for Validation 3\n",
            "79 - ETS with avg smape 8.27: \n",
            "Model Number: 80 of 162 with model ETS for Validation 3\n",
            "80 - ETS with avg smape 8.27: \n",
            "Model Number: 81 of 162 with model LastValueNaive for Validation 3\n",
            "81 - LastValueNaive with avg smape 7.74: \n",
            "Model Number: 82 of 162 with model ETS for Validation 3\n",
            "82 - ETS with avg smape 8.75: \n",
            "Model Number: 83 of 162 with model ETS for Validation 3\n",
            "83 - ETS with avg smape 8.75: \n",
            "Model Number: 84 of 162 with model AverageValueNaive for Validation 3\n",
            "84 - AverageValueNaive with avg smape 7.97: \n",
            "Model Number: 85 of 162 with model UnobservedComponents for Validation 3\n",
            "85 - UnobservedComponents with avg smape 9.02: \n",
            "Model Number: 86 of 162 with model UnobservedComponents for Validation 3\n",
            "86 - UnobservedComponents with avg smape 9.01: \n",
            "Model Number: 87 of 162 with model ETS for Validation 3\n",
            "87 - ETS with avg smape 7.12: \n",
            "Model Number: 88 of 162 with model UnobservedComponents for Validation 3\n",
            "88 - UnobservedComponents with avg smape 8.98: \n",
            "Model Number: 89 of 162 with model UnobservedComponents for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in add\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89 - UnobservedComponents with avg smape 8.99: \n",
            "Model Number: 90 of 162 with model UnobservedComponents for Validation 3\n",
            "90 - UnobservedComponents with avg smape 9.11: \n",
            "Model Number: 91 of 162 with model UnobservedComponents for Validation 3\n",
            "91 - UnobservedComponents with avg smape 9.11: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 92 of 162 with model Theta for Validation 3\n",
            "92 - Theta with avg smape 9.54: \n",
            "Model Number: 93 of 162 with model Theta for Validation 3\n",
            "93 - Theta with avg smape 9.55: \n",
            "Model Number: 94 of 162 with model UnobservedComponents for Validation 3\n",
            "94 - UnobservedComponents with avg smape 9.36: \n",
            "Model Number: 95 of 162 with model LastValueNaive for Validation 3\n",
            "95 - LastValueNaive with avg smape 9.22: \n",
            "Model Number: 96 of 162 with model LastValueNaive for Validation 3\n",
            "96 - LastValueNaive with avg smape 9.22: \n",
            "Model Number: 97 of 162 with model LastValueNaive for Validation 3\n",
            "97 - LastValueNaive with avg smape 9.31: \n",
            "Model Number: 98 of 162 with model Theta for Validation 3\n",
            "98 - Theta with avg smape 10.05: \n",
            "Model Number: 99 of 162 with model AverageValueNaive for Validation 3\n",
            "99 - AverageValueNaive with avg smape 4.03: \n",
            "Model Number: 100 of 162 with model LastValueNaive for Validation 3\n",
            "100 - LastValueNaive with avg smape 8.97: \n",
            "Model Number: 101 of 162 with model Theta for Validation 3\n",
            "101 - Theta with avg smape 16.76: \n",
            "Model Number: 102 of 162 with model LastValueNaive for Validation 3\n",
            "102 - LastValueNaive with avg smape 8.55: \n",
            "Model Number: 103 of 162 with model Theta for Validation 3\n",
            "103 - Theta with avg smape 10.78: \n",
            "Model Number: 104 of 162 with model Theta for Validation 3\n",
            "104 - Theta with avg smape 10.57: \n",
            "Model Number: 105 of 162 with model Theta for Validation 3\n",
            "105 - Theta with avg smape 10.57: \n",
            "Model Number: 106 of 162 with model Theta for Validation 3\n",
            "106 - Theta with avg smape 10.57: \n",
            "Model Number: 107 of 162 with model Theta for Validation 3\n",
            "107 - Theta with avg smape 10.61: \n",
            "Model Number: 108 of 162 with model LastValueNaive for Validation 3\n",
            "108 - LastValueNaive with avg smape 8.42: \n",
            "Model Number: 109 of 162 with model LastValueNaive for Validation 3\n",
            "109 - LastValueNaive with avg smape 8.42: \n",
            "Model Number: 110 of 162 with model AverageValueNaive for Validation 3\n",
            "110 - AverageValueNaive with avg smape 10.5: \n",
            "Model Number: 111 of 162 with model AverageValueNaive for Validation 3\n",
            "111 - AverageValueNaive with avg smape 11.27: \n",
            "Model Number: 112 of 162 with model AverageValueNaive for Validation 3\n",
            "112 - AverageValueNaive with avg smape 11.27: \n",
            "Model Number: 113 of 162 with model AverageValueNaive for Validation 3\n",
            "113 - AverageValueNaive with avg smape 11.26: \n",
            "Model Number: 114 of 162 with model GLS for Validation 3\n",
            "114 - GLS with avg smape 13.85: \n",
            "Model Number: 115 of 162 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115 - FBProphet with avg smape 140.09: \n",
            "Model Number: 116 of 162 with model GLS for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116 - GLS with avg smape 14.4: \n",
            "Model Number: 117 of 162 with model FBProphet for Validation 3\n",
            "117 - FBProphet with avg smape 8.85: \n",
            "Model Number: 118 of 162 with model GLS for Validation 3\n",
            "118 - GLS with avg smape 6.42: \n",
            "Model Number: 119 of 162 with model SectionalMotif for Validation 3\n",
            "119 - SectionalMotif with avg smape 13.31: \n",
            "Model Number: 120 of 162 with model GLS for Validation 3\n",
            "120 - GLS with avg smape 12.27: \n",
            "Model Number: 121 of 162 with model GLS for Validation 3\n",
            "121 - GLS with avg smape 12.27: \n",
            "Model Number: 122 of 162 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122 - FBProphet with avg smape 12.27: \n",
            "Model Number: 123 of 162 with model GLS for Validation 3\n",
            "123 - GLS with avg smape 12.38: \n",
            "Model Number: 124 of 162 with model SectionalMotif for Validation 3\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (75)') in model 124: SectionalMotif\n",
            "Model Number: 125 of 162 with model GLS for Validation 3\n",
            "125 - GLS with avg smape 12.27: \n",
            "Model Number: 126 of 162 with model GLS for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126 - GLS with avg smape 11.84: \n",
            "Model Number: 127 of 162 with model SectionalMotif for Validation 3\n",
            "127 - SectionalMotif with avg smape 12.46: \n",
            "Model Number: 128 of 162 with model SectionalMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128 - SectionalMotif with avg smape 15.4: \n",
            "Model Number: 129 of 162 with model SectionalMotif for Validation 3\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (80)') in model 129: SectionalMotif\n",
            "Model Number: 130 of 162 with model FBProphet for Validation 3\n",
            "130 - FBProphet with avg smape 11.82: \n",
            "Model Number: 131 of 162 with model SectionalMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 - SectionalMotif with avg smape 14.08: \n",
            "Model Number: 132 of 162 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132 - FBProphet with avg smape 13.19: \n",
            "Model Number: 133 of 162 with model FBProphet for Validation 3\n",
            "133 - FBProphet with avg smape 11.86: \n",
            "Model Number: 134 of 162 with model UnivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134 - UnivariateRegression with avg smape 14.79: \n",
            "Model Number: 135 of 162 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 - FBProphet with avg smape 12.69: \n",
            "Model Number: 136 of 162 with model FBProphet for Validation 3\n",
            "136 - FBProphet with avg smape 14.04: \n",
            "Model Number: 137 of 162 with model NVAR for Validation 3\n",
            "137 - NVAR with avg smape 12.59: \n",
            "Model Number: 138 of 162 with model NVAR for Validation 3\n",
            "138 - NVAR with avg smape 12.59: \n",
            "Model Number: 139 of 162 with model NVAR for Validation 3\n",
            "139 - NVAR with avg smape 12.64: \n",
            "Model Number: 140 of 162 with model NVAR for Validation 3\n",
            "140 - NVAR with avg smape 12.64: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 141 of 162 with model FBProphet for Validation 3\n",
            "141 - FBProphet with avg smape 13.88: \n",
            "Model Number: 142 of 162 with model NVAR for Validation 3\n",
            "142 - NVAR with avg smape 12.71: \n",
            "Model Number: 143 of 162 with model NVAR for Validation 3\n",
            "143 - NVAR with avg smape 11.85: \n",
            "Model Number: 144 of 162 with model NVAR for Validation 3\n",
            "144 - NVAR with avg smape 12.78: \n",
            "Model Number: 145 of 162 with model ConstantNaive for Validation 3\n",
            "145 - ConstantNaive with avg smape 12.52: \n",
            "Model Number: 146 of 162 with model ConstantNaive for Validation 3\n",
            "146 - ConstantNaive with avg smape 12.26: \n",
            "Model Number: 147 of 162 with model ConstantNaive for Validation 3\n",
            "147 - ConstantNaive with avg smape 12.26: \n",
            "Model Number: 148 of 162 with model ConstantNaive for Validation 3\n",
            "148 - ConstantNaive with avg smape 12.27: \n",
            "Model Number: 149 of 162 with model ConstantNaive for Validation 3\n",
            "149 - ConstantNaive with avg smape 12.24: \n",
            "Model Number: 150 of 162 with model NVAR for Validation 3\n",
            "150 - NVAR with avg smape 11.7: \n",
            "Model Number: 151 of 162 with model NVAR for Validation 3\n",
            "151 - NVAR with avg smape 11.7: \n",
            "Model Number: 152 of 162 with model ConstantNaive for Validation 3\n",
            "152 - ConstantNaive with avg smape 12.67: \n",
            "Model Number: 153 of 162 with model ConstantNaive for Validation 3\n",
            "153 - ConstantNaive with avg smape 12.73: \n",
            "Model Number: 154 of 162 with model ConstantNaive for Validation 3\n",
            "154 - ConstantNaive with avg smape 15.1: \n",
            "Model Number: 155 of 162 with model ConstantNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155 - ConstantNaive with avg smape 15.1: \n",
            "Model Number: 156 of 162 with model UnivariateRegression for Validation 3\n",
            "156 - UnivariateRegression with avg smape 8.31: \n",
            "Model Number: 157 of 162 with model SectionalMotif for Validation 3\n",
            "157 - SectionalMotif with avg smape 9.38: \n",
            "Model Number: 158 of 162 with model UnivariateRegression for Validation 3\n",
            "158 - UnivariateRegression with avg smape 18.6: \n",
            "Model Number: 159 of 162 with model UnivariateRegression for Validation 3\n",
            "159 - UnivariateRegression with avg smape 32.61: \n",
            "Model Number: 160 of 162 with model UnivariateRegression for Validation 3\n",
            "160 - UnivariateRegression with avg smape 33.53: \n",
            "Model Number: 161 of 162 with model UnivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in power\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161 - UnivariateRegression with avg smape 33.13: \n",
            "Model Number: 162 of 162 with model GLM for Validation 3\n",
            "162 - GLM with avg smape 59.35: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 90196.97974325728, tolerance: 1420.2004159292037\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passengers Forecast\n",
            "            #Passengers\n",
            "1961-01-01   449.340453\n",
            "1961-02-01   410.529904\n",
            "1961-03-01   448.920565\n",
            "1961-04-01   481.169971\n",
            "1961-05-01   502.400000\n",
            "1961-06-01   571.769322\n",
            "1961-07-01   663.926903\n",
            "1961-08-01   641.547812\n",
            "1961-09-01   535.561613\n",
            "1961-10-01   488.242659\n",
            "1961-11-01   419.980000\n",
            "1961-12-01   467.680000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Passengers Forecast\")\n",
        "print(forecast)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QVYMH1zUCE8",
        "outputId": "50a2825c-ee81-4392-fd82-bc18b4efc614"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passengers Forecast\n",
            "            #Passengers\n",
            "1961-01-01   449.340453\n",
            "1961-02-01   410.529904\n",
            "1961-03-01   448.920565\n",
            "1961-04-01   481.169971\n",
            "1961-05-01   502.400000\n",
            "1961-06-01   571.769322\n",
            "1961-07-01   663.926903\n",
            "1961-08-01   641.547812\n",
            "1961-09-01   535.561613\n",
            "1961-10-01   488.242659\n",
            "1961-11-01   419.980000\n",
            "1961-12-01   467.680000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data_air=data.set_index('month')\n",
        "plt.plot(np.arange(144), data_air)\n",
        "plt.plot(np.arange(144, 144+12), forecast)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N6Cib3jLY-Km",
        "outputId": "11372748-0f6f-4f6d-c9d5-34cb9304e13b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jZcTLhU7ZAu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Darts\n",
        "\n",
        "Darts is another time series Python library developed by Unit8 for easy manipulation and forecasting of time series. This idea was to make darts as simple to use as sklearn for time-series. Darts attempts to smooth the overall process of using time series in machine learning. Darts has two models: Regression models (predicts output with time as input) and Forecasting models (predicts future output based on past values)."
      ],
      "metadata": {
        "id": "a6DPpqI7ZNup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install darts"
      ],
      "metadata": {
        "id": "U0M8FFKyZSJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from darts import TimeSeries\n",
        "from darts.models import ExponentialSmoothing\n",
        "\n",
        "# Create a TimeSeries, specifying the time and value columns\n",
        "series = TimeSeries.from_dataframe(data, 'month', '#Passengers')\n",
        "\n",
        "# Set aside the last 36 months as a validation series\n",
        "train, val = series[:-36], series[-36:]"
      ],
      "metadata": {
        "id": "KJuOHK6SZU2z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from darts.models import ExponentialSmoothing\n",
        "\n",
        "model = ExponentialSmoothing()\n",
        "model.fit(train)\n",
        "prediction = model.predict(len(val), num_samples=1000)"
      ],
      "metadata": {
        "id": "vV-1WOVpZfxb",
        "outputId": "eb7504d3-d70a-456d-ca45-82ae242df13e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:429: FutureWarning:\n",
            "\n",
            "After 0.13 initialization must be handled at model creation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "series.plot()\n",
        "prediction.plot(label='forecast', low_quantile=0.05, high_quantile=0.95)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "W4nw7f0tZi6d",
        "outputId": "69b401de-c10f-4753-a5cf-30973e570908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9e13b38e10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Result:**\n",
        "\n",
        "Yes the results are slightly differ by comparing each other, most probably the values are closer to one another. \n",
        "I prefer Darts as it is easy to manipulate and forecast of timeseries and provides accurate results also we can easily visualize the results"
      ],
      "metadata": {
        "id": "mDY7RtaPbLfT"
      }
    }
  ]
}